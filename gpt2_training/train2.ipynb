{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:31dar30s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df4c667246046bea2b297ad279cc789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>▇▇█████▇█▇▆▇▇▅▇▇▆▅▆▅▅▆▄▅▄▄▃▃▄▃▃▂▂▂▁▂▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁▁</td></tr><tr><td>train/train_loss</td><td>█▁</td></tr><tr><td>train/train_runtime</td><td>▁█</td></tr><tr><td>train/train_samples_per_second</td><td>█▁</td></tr><tr><td>train/train_steps_per_second</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>40.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.4755</td></tr><tr><td>train/total_flos</td><td>28125637632000.0</td></tr><tr><td>train/train_loss</td><td>0.29995</td></tr><tr><td>train/train_runtime</td><td>164.8435</td></tr><tr><td>train/train_samples_per_second</td><td>4.853</td></tr><tr><td>train/train_steps_per_second</td><td>1.213</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">charmed-energy-1</strong>: <a href=\"https://wandb.ai/piazza-qabot/gpt2-pretrain/runs/31dar30s\" target=\"_blank\">https://wandb.ai/piazza-qabot/gpt2-pretrain/runs/31dar30s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231105_154955-31dar30s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:31dar30s). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fs01/home/brandon/internship/Uncover_implicit_bias/gpt2_training/wandb/run-20231105_173018-pkp7axc0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/piazza-qabot/gpt2-pretrain/runs/pkp7axc0\" target=\"_blank\">rich-jazz-2</a></strong> to <a href=\"https://wandb.ai/piazza-qabot/gpt2-pretrain\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/piazza-qabot/gpt2-pretrain/runs/pkp7axc0?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f08b9c47280>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"gpt2-pretrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
    "\n",
    "df = pd.read_csv('/h/brandon/internship/Uncover_implicit_bias/gpt2_training/data/ROCStories_winter2017.csv')\n",
    "df = df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storyid</th>\n",
       "      <th>storytitle</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence3</th>\n",
       "      <th>sentence4</th>\n",
       "      <th>sentence5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bbe6d11-1e2e-413c-bf81-eaea05f4f1bd</td>\n",
       "      <td>David Drops the Weight</td>\n",
       "      <td>David noticed he had put on a lot of weight re...</td>\n",
       "      <td>He examined his habits to try and figure out t...</td>\n",
       "      <td>He realized he'd been eating too much fast foo...</td>\n",
       "      <td>He stopped going to burger places and started ...</td>\n",
       "      <td>After a few weeks, he started to feel much bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0beabab2-fb49-460e-a6e6-f35a202e3348</td>\n",
       "      <td>Frustration</td>\n",
       "      <td>Tom had a very short temper.</td>\n",
       "      <td>One day a guest made him very angry.</td>\n",
       "      <td>He punched a hole in the wall of his house.</td>\n",
       "      <td>Tom's guest became afraid and left quickly.</td>\n",
       "      <td>Tom sat on his couch filled with regret about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87da1a22-df0b-410c-b186-439700b70ba6</td>\n",
       "      <td>Marcus Buys Khakis</td>\n",
       "      <td>Marcus needed clothing for a business casual e...</td>\n",
       "      <td>All of his clothes were either too formal or t...</td>\n",
       "      <td>He decided to buy a pair of khakis.</td>\n",
       "      <td>The pair he bought fit him perfectly.</td>\n",
       "      <td>Marcus was happy to have the right clothes for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d16bcd6-692a-4fc0-8e7c-4a6f81d9efa9</td>\n",
       "      <td>Different Opinions</td>\n",
       "      <td>Bobby thought Bill should buy a trailer and ha...</td>\n",
       "      <td>Bill thought a truck would be better for what ...</td>\n",
       "      <td>Bobby pointed out two vehicles were much more ...</td>\n",
       "      <td>Bill was set in his ways with conventional thi...</td>\n",
       "      <td>He ended up buying the truck he wanted despite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c71bb23b-7731-4233-8298-76ba6886cee1</td>\n",
       "      <td>Overcoming shortcomings</td>\n",
       "      <td>John was a pastor with a very bad memory.</td>\n",
       "      <td>He tried to memorize his sermons many days in ...</td>\n",
       "      <td>He decided to learn to sing to overcome his ha...</td>\n",
       "      <td>He then made all his sermons into music and sa...</td>\n",
       "      <td>His congregation was delighted and so was he.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4d7b022e-25d2-4300-a9b0-24ab35f4045b</td>\n",
       "      <td>Melody's trip to the aquarium.</td>\n",
       "      <td>Melody's parents surprised her with a trip to ...</td>\n",
       "      <td>Melody took a nap during the two hour car ride...</td>\n",
       "      <td>When they arrived, Melody was energetic and ex...</td>\n",
       "      <td>At the aquarium Melody saw sharks, tropical fi...</td>\n",
       "      <td>After five hours at the aquarium, Melody and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8036c905-f23e-4976-83a1-85d679b5e0c2</td>\n",
       "      <td>Pop Quiz</td>\n",
       "      <td>The math teacher announced a pop quiz as class...</td>\n",
       "      <td>While some students complained, he began passi...</td>\n",
       "      <td>I took out my pencil and began to work.</td>\n",
       "      <td>About 5 minutes later, I finished.</td>\n",
       "      <td>I stood up feeling confident and turned it in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77338898-07d4-4143-8451-284540c8b082</td>\n",
       "      <td>My first girlfriend</td>\n",
       "      <td>My first girlfriend i met on the internet.</td>\n",
       "      <td>She lives about 4 hours away from me.</td>\n",
       "      <td>Finally after 2 years we met each other.</td>\n",
       "      <td>She stayed with me for a week or two.</td>\n",
       "      <td>We decided we couldn't be apart so she moved i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>110fafd1-2bb7-4ffe-aac7-475706165d41</td>\n",
       "      <td>Charlie Horse</td>\n",
       "      <td>I got Charlie Horse when I was four years old.</td>\n",
       "      <td>He's a brown stuffed horse, and at 35 I still ...</td>\n",
       "      <td>He was my best friend, and always laid at the ...</td>\n",
       "      <td>I laid him next to me, smelling his soft fur e...</td>\n",
       "      <td>I liked to listen to my radio as I fell asleep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13573c2e-5eed-40eb-bbe5-ed259b5c76a6</td>\n",
       "      <td>Corn</td>\n",
       "      <td>Laura loved corn.</td>\n",
       "      <td>So she decided to grow some in her backyard.</td>\n",
       "      <td>The whole process of growing them made her ver...</td>\n",
       "      <td>But she realized that they required too much w...</td>\n",
       "      <td>So Laura quickly abandoned her corn garden idea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c400d38a-54fc-45da-99ed-558fcfc81016</td>\n",
       "      <td>New Hair Color</td>\n",
       "      <td>Andy was invited to a Halloween party.</td>\n",
       "      <td>Andy figured that for dramatic effect, he shou...</td>\n",
       "      <td>Since Andy's costume was green, Andy decided o...</td>\n",
       "      <td>After the stylist finished the coloring, Andy ...</td>\n",
       "      <td>Andy was disappointed with his new, bold, gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8fbef343-8806-4bcf-9326-08ca6ebf6cb9</td>\n",
       "      <td>Winner</td>\n",
       "      <td>Luke was playing hockey at school.</td>\n",
       "      <td>The game was tied and almost over.</td>\n",
       "      <td>Then Luke made the winning shot!</td>\n",
       "      <td>Everybody cheered!</td>\n",
       "      <td>Luke was so proud of himself!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3be3719a-ae77-4106-88ea-988afb19db99</td>\n",
       "      <td>Cross country</td>\n",
       "      <td>Robbie was competing in a cross country meet.</td>\n",
       "      <td>He was halfway through when his leg cramped up.</td>\n",
       "      <td>Robbie wasn't sure he could go on.</td>\n",
       "      <td>He stopped for a minute and stretched his bad ...</td>\n",
       "      <td>Robbie began to run again and finished the rac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a8d6e66b-da81-4dc7-a470-67f2ab32b9e6</td>\n",
       "      <td>Traffic Troubles</td>\n",
       "      <td>Jude was very excited about his college gradua...</td>\n",
       "      <td>On the way to the arena, he got stuck in traffic.</td>\n",
       "      <td>He only had an hour before the ceremony started.</td>\n",
       "      <td>He thought he wasn't going to be able to make ...</td>\n",
       "      <td>Luckily, the traffic cleared up in time for hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8fba56f8-e9f8-45a9-a5b9-8adf1744e1ba</td>\n",
       "      <td>Not Santa</td>\n",
       "      <td>Beth sent a letter to Santa Claus.</td>\n",
       "      <td>She received a letter back in the mail.</td>\n",
       "      <td>Beth did not think that it sounded like the re...</td>\n",
       "      <td>She sent another letter calling that Santa a f...</td>\n",
       "      <td>She did not receive another letter back in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>038ac579-052e-4f5d-837a-772e98961cc0</td>\n",
       "      <td>Miss Fussy</td>\n",
       "      <td>Our granddaughter Anna is very fussy about her...</td>\n",
       "      <td>She is only two, but wants to pick her outfits.</td>\n",
       "      <td>Today her mom wanted Anna to wear a dress.</td>\n",
       "      <td>Anna started crying.</td>\n",
       "      <td>They let her wear a t-shirt and shorts instead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b94e1810-9869-4af6-bb74-b4a51c46f3d2</td>\n",
       "      <td>Getting to the Store</td>\n",
       "      <td>Jake needed a ride to the store.</td>\n",
       "      <td>His girlfriend was working and wouldn't take him.</td>\n",
       "      <td>His brother was in the middle of a movie and s...</td>\n",
       "      <td>Jake decided to take the bus to the store.</td>\n",
       "      <td>He got what he needed all by himself.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6be1d668-0d92-45bb-a423-bd12d00c1472</td>\n",
       "      <td>The Sale</td>\n",
       "      <td>I'd been looking for a stand for my TV.</td>\n",
       "      <td>I looked everywhere, but the ones I saw were e...</td>\n",
       "      <td>I happened upon a yard sale on my way home.</td>\n",
       "      <td>She had a stand that was perfect, and cheap.</td>\n",
       "      <td>It looks great in my den.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c50cf35d-564d-40c9-8784-80b4fdec9d16</td>\n",
       "      <td>Prescription</td>\n",
       "      <td>Sally had a root canal this morning, as she ha...</td>\n",
       "      <td>After the procedure, the dentist wrote her a p...</td>\n",
       "      <td>She headed straight to the pharmacy to fill he...</td>\n",
       "      <td>She handed the prescription to the technician ...</td>\n",
       "      <td>The technician called her name and she paid fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ae7e744e-fd27-46c2-befb-7e8427cb679c</td>\n",
       "      <td>Storm</td>\n",
       "      <td>My dog is terrified of thunder.</td>\n",
       "      <td>There was a storm today.</td>\n",
       "      <td>He came running into my office.</td>\n",
       "      <td>He hid in the kneehole of my desk, trembling.</td>\n",
       "      <td>Once the storm was over, he acted like a brave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 storyid                      storytitle  \\\n",
       "0   8bbe6d11-1e2e-413c-bf81-eaea05f4f1bd          David Drops the Weight   \n",
       "1   0beabab2-fb49-460e-a6e6-f35a202e3348                     Frustration   \n",
       "2   87da1a22-df0b-410c-b186-439700b70ba6              Marcus Buys Khakis   \n",
       "3   2d16bcd6-692a-4fc0-8e7c-4a6f81d9efa9              Different Opinions   \n",
       "4   c71bb23b-7731-4233-8298-76ba6886cee1         Overcoming shortcomings   \n",
       "5   4d7b022e-25d2-4300-a9b0-24ab35f4045b  Melody's trip to the aquarium.   \n",
       "6   8036c905-f23e-4976-83a1-85d679b5e0c2                        Pop Quiz   \n",
       "7   77338898-07d4-4143-8451-284540c8b082             My first girlfriend   \n",
       "8   110fafd1-2bb7-4ffe-aac7-475706165d41                   Charlie Horse   \n",
       "9   13573c2e-5eed-40eb-bbe5-ed259b5c76a6                            Corn   \n",
       "10  c400d38a-54fc-45da-99ed-558fcfc81016                  New Hair Color   \n",
       "11  8fbef343-8806-4bcf-9326-08ca6ebf6cb9                          Winner   \n",
       "12  3be3719a-ae77-4106-88ea-988afb19db99                   Cross country   \n",
       "13  a8d6e66b-da81-4dc7-a470-67f2ab32b9e6                Traffic Troubles   \n",
       "14  8fba56f8-e9f8-45a9-a5b9-8adf1744e1ba                       Not Santa   \n",
       "15  038ac579-052e-4f5d-837a-772e98961cc0                      Miss Fussy   \n",
       "16  b94e1810-9869-4af6-bb74-b4a51c46f3d2            Getting to the Store   \n",
       "17  6be1d668-0d92-45bb-a423-bd12d00c1472                        The Sale   \n",
       "18  c50cf35d-564d-40c9-8784-80b4fdec9d16                    Prescription   \n",
       "19  ae7e744e-fd27-46c2-befb-7e8427cb679c                           Storm   \n",
       "\n",
       "                                            sentence1  \\\n",
       "0   David noticed he had put on a lot of weight re...   \n",
       "1                        Tom had a very short temper.   \n",
       "2   Marcus needed clothing for a business casual e...   \n",
       "3   Bobby thought Bill should buy a trailer and ha...   \n",
       "4           John was a pastor with a very bad memory.   \n",
       "5   Melody's parents surprised her with a trip to ...   \n",
       "6   The math teacher announced a pop quiz as class...   \n",
       "7          My first girlfriend i met on the internet.   \n",
       "8      I got Charlie Horse when I was four years old.   \n",
       "9                                   Laura loved corn.   \n",
       "10             Andy was invited to a Halloween party.   \n",
       "11                 Luke was playing hockey at school.   \n",
       "12      Robbie was competing in a cross country meet.   \n",
       "13  Jude was very excited about his college gradua...   \n",
       "14                 Beth sent a letter to Santa Claus.   \n",
       "15  Our granddaughter Anna is very fussy about her...   \n",
       "16                   Jake needed a ride to the store.   \n",
       "17            I'd been looking for a stand for my TV.   \n",
       "18  Sally had a root canal this morning, as she ha...   \n",
       "19                    My dog is terrified of thunder.   \n",
       "\n",
       "                                            sentence2  \\\n",
       "0   He examined his habits to try and figure out t...   \n",
       "1                One day a guest made him very angry.   \n",
       "2   All of his clothes were either too formal or t...   \n",
       "3   Bill thought a truck would be better for what ...   \n",
       "4   He tried to memorize his sermons many days in ...   \n",
       "5   Melody took a nap during the two hour car ride...   \n",
       "6   While some students complained, he began passi...   \n",
       "7               She lives about 4 hours away from me.   \n",
       "8   He's a brown stuffed horse, and at 35 I still ...   \n",
       "9        So she decided to grow some in her backyard.   \n",
       "10  Andy figured that for dramatic effect, he shou...   \n",
       "11                 The game was tied and almost over.   \n",
       "12    He was halfway through when his leg cramped up.   \n",
       "13  On the way to the arena, he got stuck in traffic.   \n",
       "14            She received a letter back in the mail.   \n",
       "15    She is only two, but wants to pick her outfits.   \n",
       "16  His girlfriend was working and wouldn't take him.   \n",
       "17  I looked everywhere, but the ones I saw were e...   \n",
       "18  After the procedure, the dentist wrote her a p...   \n",
       "19                           There was a storm today.   \n",
       "\n",
       "                                            sentence3  \\\n",
       "0   He realized he'd been eating too much fast foo...   \n",
       "1         He punched a hole in the wall of his house.   \n",
       "2                 He decided to buy a pair of khakis.   \n",
       "3   Bobby pointed out two vehicles were much more ...   \n",
       "4   He decided to learn to sing to overcome his ha...   \n",
       "5   When they arrived, Melody was energetic and ex...   \n",
       "6             I took out my pencil and began to work.   \n",
       "7            Finally after 2 years we met each other.   \n",
       "8   He was my best friend, and always laid at the ...   \n",
       "9   The whole process of growing them made her ver...   \n",
       "10  Since Andy's costume was green, Andy decided o...   \n",
       "11                   Then Luke made the winning shot!   \n",
       "12                 Robbie wasn't sure he could go on.   \n",
       "13   He only had an hour before the ceremony started.   \n",
       "14  Beth did not think that it sounded like the re...   \n",
       "15         Today her mom wanted Anna to wear a dress.   \n",
       "16  His brother was in the middle of a movie and s...   \n",
       "17        I happened upon a yard sale on my way home.   \n",
       "18  She headed straight to the pharmacy to fill he...   \n",
       "19                    He came running into my office.   \n",
       "\n",
       "                                            sentence4  \\\n",
       "0   He stopped going to burger places and started ...   \n",
       "1         Tom's guest became afraid and left quickly.   \n",
       "2               The pair he bought fit him perfectly.   \n",
       "3   Bill was set in his ways with conventional thi...   \n",
       "4   He then made all his sermons into music and sa...   \n",
       "5   At the aquarium Melody saw sharks, tropical fi...   \n",
       "6                  About 5 minutes later, I finished.   \n",
       "7               She stayed with me for a week or two.   \n",
       "8   I laid him next to me, smelling his soft fur e...   \n",
       "9   But she realized that they required too much w...   \n",
       "10  After the stylist finished the coloring, Andy ...   \n",
       "11                                 Everybody cheered!   \n",
       "12  He stopped for a minute and stretched his bad ...   \n",
       "13  He thought he wasn't going to be able to make ...   \n",
       "14  She sent another letter calling that Santa a f...   \n",
       "15                               Anna started crying.   \n",
       "16         Jake decided to take the bus to the store.   \n",
       "17       She had a stand that was perfect, and cheap.   \n",
       "18  She handed the prescription to the technician ...   \n",
       "19      He hid in the kneehole of my desk, trembling.   \n",
       "\n",
       "                                            sentence5  \n",
       "0   After a few weeks, he started to feel much bet...  \n",
       "1   Tom sat on his couch filled with regret about ...  \n",
       "2   Marcus was happy to have the right clothes for...  \n",
       "3   He ended up buying the truck he wanted despite...  \n",
       "4       His congregation was delighted and so was he.  \n",
       "5   After five hours at the aquarium, Melody and h...  \n",
       "6      I stood up feeling confident and turned it in.  \n",
       "7   We decided we couldn't be apart so she moved i...  \n",
       "8   I liked to listen to my radio as I fell asleep...  \n",
       "9    So Laura quickly abandoned her corn garden idea.  \n",
       "10  Andy was disappointed with his new, bold, gree...  \n",
       "11                      Luke was so proud of himself!  \n",
       "12  Robbie began to run again and finished the rac...  \n",
       "13  Luckily, the traffic cleared up in time for hi...  \n",
       "14  She did not receive another letter back in the...  \n",
       "15    They let her wear a t-shirt and shorts instead.  \n",
       "16              He got what he needed all by himself.  \n",
       "17                          It looks great in my den.  \n",
       "18  The technician called her name and she paid fo...  \n",
       "19  Once the storm was over, he acted like a brave...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to concatenate the story title with the sentences\n",
    "def concatenate_story_elements(row):\n",
    "    title = row['storytitle']\n",
    "    sentences = ' '.join(row[['sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5']].tolist())\n",
    "    return f'{title} [SEP] {sentences}'\n",
    "\n",
    "# Apply the function to each row\n",
    "df['story'] = df.apply(concatenate_story_elements, axis=1)\n",
    "\n",
    "stories_data = list(df['story'])\n",
    "\n",
    "\n",
    "# Convert list of strings to a dictionary with a key\n",
    "stories_dict = {'story': stories_data}\n",
    "\n",
    "# Convert the dictionary to a Hugging Face Dataset\n",
    "dataset = Dataset.from_dict(stories_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': \"David Drops the Weight [SEP] David noticed he had put on a lot of weight recently. He examined his habits to try and figure out the reason. He realized he'd been eating too much fast food lately. He stopped going to burger places and started a vegetarian diet. After a few weeks, he started to feel much better.\"}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /h/brandon/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /h/brandon/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /h/brandon/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /h/brandon/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /h/brandon/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Adding [SEP] to the vocabulary\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Adding [PAD] to the vocabulary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The id for [SEP] is: 50257\n",
      "The token for id 50257 is: [SEP]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875e59d6061c439182aba315aa29a390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some samples from the training set:\n",
      "\n",
      "Sample 1:\n",
      "David Drops the Weight [SEP] David noticed he had put on a lot of weight recently. He examined his habits to try and figure out the reason. He realized he'd been eating too much fast food lately. He stopped going to burger places and started a vegetarian diet. After a few weeks, he started to feel much better.\n",
      "\n",
      "Sample 2:\n",
      "Frustration [SEP] Tom had a very short temper. One day a guest made him very angry. He punched a hole in the wall of his house. Tom's guest became afraid and left quickly. Tom sat on his couch filled with regret about his actions.\n",
      "\n",
      "Sample 3:\n",
      "Marcus Buys Khakis [SEP] Marcus needed clothing for a business casual event. All of his clothes were either too formal or too casual. He decided to buy a pair of khakis. The pair he bought fit him perfectly. Marcus was happy to have the right clothes for the event.\n",
      "\n",
      "Sample 4:\n",
      "Different Opinions [SEP] Bobby thought Bill should buy a trailer and haul it with his car. Bill thought a truck would be better for what he needed. Bobby pointed out two vehicles were much more expensive. Bill was set in his ways with conventional thinking. He ended up buying the truck he wanted despite Bobby's advice.\n",
      "\n",
      "Sample 5:\n",
      "Overcoming shortcomings [SEP] John was a pastor with a very bad memory. He tried to memorize his sermons many days in advance but to no avail. He decided to learn to sing to overcome his handicap. He then made all his sermons into music and sang them on Sundays. His congregation was delighted and so was he.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'sep_token': '[SEP]'})\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "token_id = tokenizer.convert_tokens_to_ids('[SEP]')  # Replace <TITLE> with your token\n",
    "print(f\"The id for [SEP] is: {token_id}\")\n",
    "\n",
    "# Convert id to token\n",
    "token_id = 50257\n",
    "token = tokenizer.convert_ids_to_tokens(token_id)\n",
    "print(f\"The token for id {token_id} is: {token}\")\n",
    "\n",
    "# random init for added tokens\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "# Define a function to apply to each example\n",
    "def preprocess_function(example):\n",
    "    # Modify examples here (e.g., tokenize text)\n",
    "    return tokenizer(example[\"story\"]) \n",
    "\n",
    "# Apply the function to the dataset\n",
    "processed_dataset = dataset.map(preprocess_function)\n",
    "\n",
    "def check_token_ids(dataset, tokenizer):\n",
    "    # print('Checking token ids')\n",
    "    for sample in processed_dataset:\n",
    "        print(sample)\n",
    "        input_ids = sample[\"input_ids\"]\n",
    "        if max(input_ids) >= len(tokenizer):\n",
    "            print(f\"Invalid token ID found: {max(input_ids)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to decode the token IDs\n",
    "def decode_sample(token_ids):\n",
    "    return tokenizer.decode(token_ids, clean_up_tokenization_spaces=True, skip_special_tokens=False)\n",
    "\n",
    "# Visualize the first few samples from train_dataset\n",
    "print(\"Some samples from the training set:\\n\")\n",
    "for i in range(5):  # let's print out the first 5 samples\n",
    "    token_ids = processed_dataset[i]['input_ids']  # get the token IDs for the i-th sample\n",
    "    text = decode_sample(token_ids)  # decode the token IDs to text\n",
    "    print(f\"Sample {i + 1}:\\n{text}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False \n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/checkpoint/brandon/internship',         # Output directory\n",
    "    overwrite_output_dir=False,      # Overwrite the content of the output directory\n",
    "    num_train_epochs=50,             # Number of training epochs\n",
    "    per_device_train_batch_size=4,  # Batch size for training\n",
    "    per_device_eval_batch_size=4,   # Batch size for evaluation\n",
    "    # eval_steps=400,                 # Evaluation step\n",
    "    save_steps=800,                 # After # steps model is saved\n",
    "    warmup_steps=500,               # Warmup steps\n",
    "    # logging_dir='./logs',\n",
    "    # logging_steps=1,\n",
    "    report_to='wandb',\n",
    "    # evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3\n",
    "    # do_eval=False\n",
    ")\n",
    "\n",
    "#Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=processed_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: story. If story are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "/h/brandon/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 250\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 03:25, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-5\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-5/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-5/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-75] due to args.save_total_limit\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-80] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-10\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-10/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-10/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-85] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-15\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-15/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-15/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-90] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-20\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-20/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-20/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-5] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-25\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-25/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-25/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-10] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-30\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-30/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-30/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-15] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-35\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-35/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-35/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-20] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-40\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-40/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-40/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-25] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-45\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-45/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-45/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-30] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-50\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-50/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-50/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-35] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-55\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-55/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-55/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-40] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-60\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-60/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-60/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-45] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-65\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-65/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-65/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-50] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-70\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-70/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-70/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-55] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-75\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-75/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-75/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-60] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-80\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-80/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-80/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-65] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-85\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-85/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-85/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-70] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-90\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-90/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-90/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-75] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-95\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-95/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-95/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-80] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-100\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-100/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-100/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-85] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-105\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-105/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-105/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-90] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-110\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-110/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-110/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-95] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-115\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-115/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-115/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-100] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-120\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-120/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-120/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-105] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-125\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-125/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-125/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-110] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-130\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-130/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-130/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-115] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-135\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-135/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-135/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-120] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-140\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-140/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-140/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-125] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-145\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-145/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-145/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-130] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-150\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-150/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-150/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-135] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-155\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-155/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-155/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-140] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-160\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-160/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-145] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-165\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-165/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-165/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-150] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-170\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-170/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-170/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-155] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-175\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-175/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-175/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-160] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-180\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-180/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-180/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-165] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-185\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-185/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-185/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-170] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-190\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-190/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-190/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-175] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-195\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-195/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-195/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-180] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-200\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-200/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-185] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-205\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-205/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-205/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-190] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-210\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-210/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-210/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-195] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-215\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-215/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-215/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-200] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-220\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-220/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-220/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-205] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-225\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-225/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-225/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-210] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-230\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-230/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-230/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-215] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-235\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-235/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-235/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-220] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-240\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-240/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-240/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-225] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-245\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-245/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-245/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-230] due to args.save_total_limit\n",
      "Saving model checkpoint to /checkpoint/brandon/internship/checkpoint-250\n",
      "Configuration saved in /checkpoint/brandon/internship/checkpoint-250/config.json\n",
      "Model weights saved in /checkpoint/brandon/internship/checkpoint-250/pytorch_model.bin\n",
      "Deleting older checkpoint [/checkpoint/brandon/internship/checkpoint-235] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=20.29705859375, metrics={'train_runtime': 205.1375, 'train_samples_per_second': 4.875, 'train_steps_per_second': 1.219, 'total_flos': 35231556096000.0, 'train_loss': 20.29705859375, 'epoch': 50.0})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /checkpoint/brandon/internship/checkpoint-250/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50259\n",
      "}\n",
      "\n",
      "loading weights file /checkpoint/brandon/internship/checkpoint-250/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /checkpoint/brandon/internship/checkpoint-250/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = GPT2LMHeadModel.from_pretrained('/checkpoint/brandon/internship/checkpoint-250/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': \"David Drops the Weight [SEP] David noticed he had put on a lot of weight recently. He examined his habits to try and figure out the reason. He realized he'd been eating too much fast food lately. He stopped going to burger places and started a vegetarian diet. After a few weeks, he started to feel much better.\"}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Drops the Weight [SEP] Andy was working out at the gym. He was feeling very bloated. He took a nap and then laid it on his desk. He laid it on his desk again and stretched it. He stretched it until it was full. He then laid it on his desk again and stretched it again. He finished with a big yawn. Andy sat up feeling much better. He then laid\n"
     ]
    }
   ],
   "source": [
    "# Encode a text input\n",
    "input_text = \"David Drops the Weight [SEP]\"\n",
    "tokenize = tokenizer(input_text, return_tensors='pt')\n",
    "\n",
    "# Generate text using the model\n",
    "with torch.no_grad():\n",
    "    outputs = model_ckpt.generate(**tokenize, max_length=80)\n",
    "\n",
    "# # Decode the generated text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.4390e+00, -8.8895e+00, -1.2304e+01,  ..., -9.4687e+00,\n",
       "           1.3855e-01,  2.4230e-02],\n",
       "         [-5.4546e+01, -5.2346e+01, -5.6766e+01,  ..., -5.4277e+01,\n",
       "          -8.5421e-01,  9.8880e-01],\n",
       "         [-7.3798e+01, -7.0593e+01, -7.4685e+01,  ..., -7.1020e+01,\n",
       "          -8.6089e-01, -2.1636e-01]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get logits for the next token\n",
    "logits = outputs.last_hidden_state[:, -1, :]  # Only take the logits from the last step (token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely next token is: age\n"
     ]
    }
   ],
   "source": [
    "# Convert logits to probabilities (optional)\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "# Get the most probable next token ID\n",
    "next_token_id = torch.argmax(probabilities, dim=-1).item()\n",
    "\n",
    "# Convert the token ID to a token string\n",
    "next_token = tokenizer.decode(next_token_id)\n",
    "\n",
    "print(f\"The most likely next token is: {next_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/h/brandon/internship/Uncover_implicit_bias/gpt2_training/train2.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://localhost:12000/h/brandon/internship/Uncover_implicit_bias/gpt2_training/train2.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokenize)\n",
      "File \u001b[0;32m/pkgs/pytorch-2.0-cuda-11.8-python3.9/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py:1288\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1284\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1, but is \u001b[39m\u001b[39m{\u001b[39;00mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m when doing greedy search.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1285\u001b[0m         )\n\u001b[1;32m   1287\u001b[0m     \u001b[39m# 10. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1288\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1289\u001b[0m         input_ids,\n\u001b[1;32m   1290\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1291\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1292\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1293\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1294\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1295\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1296\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1297\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1298\u001b[0m     )\n\u001b[1;32m   1300\u001b[0m \u001b[39melif\u001b[39;00m is_sample_gen_mode:\n\u001b[1;32m   1301\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1303\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m   1304\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         renormalize_logits\u001b[39m=\u001b[39mrenormalize_logits,\n\u001b[1;32m   1309\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py:1694\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1691\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1692\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n\u001b[0;32m-> 1694\u001b[0m next_token_logits \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39;49mlogits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m   1696\u001b[0m \u001b[39m# pre-process distribution\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m next_tokens_scores \u001b[39m=\u001b[39m logits_processor(input_ids, next_token_logits)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "model.generate(**tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 0.3282,  0.1634, -0.2848,  ..., -0.2900, -0.1624, -0.2453],\n",
       "         [ 0.1982, -0.1407, -0.9012,  ..., -0.3303,  0.8158, -0.2008],\n",
       "         [-0.1792, -0.1944,  0.5873,  ..., -0.6468,  0.6148, -1.1967],\n",
       "         [ 0.2422,  0.0667, -0.5426,  ...,  0.0782, -0.3759, -0.8687]]]), past_key_values=((tensor([[[[-1.2016e+00,  1.4481e+00,  5.7732e-01,  ..., -1.1780e+00,\n",
       "           -8.3090e-01,  1.1175e+00],\n",
       "          [-1.8113e+00,  2.0688e+00,  2.3186e+00,  ..., -4.9075e-01,\n",
       "           -1.0585e+00,  1.4977e+00],\n",
       "          [-2.2764e+00,  2.6445e+00,  1.4546e+00,  ..., -5.7449e-01,\n",
       "           -1.8910e+00,  2.2348e+00],\n",
       "          [-2.9731e+00,  2.7776e+00,  2.7746e+00,  ..., -2.1127e-01,\n",
       "           -2.4039e+00,  1.8967e+00]],\n",
       "\n",
       "         [[-3.8996e-01,  8.9298e-01, -3.0889e-01,  ...,  2.4295e-01,\n",
       "            1.7322e+00, -2.7951e-01],\n",
       "          [-1.3218e+00, -7.3607e-01, -8.0886e-01,  ...,  2.3548e+00,\n",
       "            3.2257e+00, -1.1722e-01],\n",
       "          [-7.2774e-01, -1.5708e+00, -2.9586e+00,  ..., -1.6818e+00,\n",
       "            4.3636e+00,  1.9618e-01],\n",
       "          [-4.4787e-01,  2.4560e-01, -2.1018e+00,  ..., -2.0988e+00,\n",
       "            3.5808e+00, -1.5168e+00]],\n",
       "\n",
       "         [[ 2.6581e-01,  5.9036e-02,  4.6352e-01,  ..., -1.3188e+00,\n",
       "           -1.6725e+00,  8.3125e-01],\n",
       "          [ 1.0142e+00, -5.2171e-01,  6.0383e-03,  ..., -2.2176e+00,\n",
       "           -3.1228e-01,  2.0811e+00],\n",
       "          [ 3.2244e-01, -2.5671e-02,  3.2257e-01,  ..., -3.0655e+00,\n",
       "            2.1853e-01,  1.2922e+00],\n",
       "          [ 4.8502e-01,  1.2300e+00,  7.5886e-01,  ..., -3.3022e+00,\n",
       "            7.4673e-01,  1.3639e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.8354e-01, -2.5791e-01, -3.7017e-01,  ...,  1.9381e-01,\n",
       "            6.8012e-01,  7.8466e-01],\n",
       "          [ 4.5321e-01, -1.5456e-01, -1.6991e-01,  ...,  7.6247e-01,\n",
       "            1.6210e-01, -1.7920e-01],\n",
       "          [-8.4098e-02, -1.0585e-01,  6.4232e-03,  ...,  1.2018e+00,\n",
       "            6.2047e-01,  4.7034e-01],\n",
       "          [-8.0253e-02,  1.1039e-01, -5.1496e-01,  ...,  1.4143e+00,\n",
       "            2.5750e-01,  6.9503e-01]],\n",
       "\n",
       "         [[ 1.2798e+00,  1.6112e+00, -6.1141e-01,  ...,  7.0814e-02,\n",
       "            1.4014e+00, -1.4718e+00],\n",
       "          [ 8.1240e-01,  3.8610e-01, -9.3123e-01,  ..., -7.7633e-01,\n",
       "            1.4314e+00, -5.1665e-01],\n",
       "          [ 9.5328e-01,  8.1077e-01, -1.5001e-01,  ..., -1.2527e+00,\n",
       "            9.6585e-01, -9.9303e-01],\n",
       "          [ 7.0460e-01,  7.1924e-01, -1.2322e+00,  ..., -1.1225e+00,\n",
       "            1.0025e+00, -1.1040e+00]],\n",
       "\n",
       "         [[ 4.6317e-01, -7.3426e-02,  4.1425e-01,  ..., -1.2323e-01,\n",
       "            3.1783e-01,  2.0363e+00],\n",
       "          [ 4.6413e-04,  3.2736e-01,  8.3504e-01,  ...,  7.5726e-01,\n",
       "            1.2728e+00,  1.3261e+00],\n",
       "          [-1.0963e-01,  1.0541e+00,  5.9636e-02,  ...,  2.2031e-01,\n",
       "            6.5177e-01,  1.2451e+00],\n",
       "          [-2.1341e-01, -3.2124e-01, -3.8506e-01,  ..., -1.8938e-01,\n",
       "           -2.7355e-01,  1.2331e+00]]]]), tensor([[[[-0.0038,  0.1288, -0.0305,  ...,  0.0141, -0.1116,  0.1494],\n",
       "          [ 0.0919,  0.2329, -0.1784,  ...,  0.1395, -0.1062,  0.1717],\n",
       "          [-0.0494,  0.0060, -0.0268,  ...,  0.1294, -0.0483, -0.0728],\n",
       "          [ 0.0705,  0.0524, -0.0675,  ..., -0.1450, -0.1980,  0.2636]],\n",
       "\n",
       "         [[ 0.3983,  0.2734, -0.1539,  ..., -0.5770, -0.2557,  0.1472],\n",
       "          [ 0.4451,  0.1268, -0.2398,  ...,  0.1182,  0.7302,  0.0046],\n",
       "          [ 0.7734, -0.1373,  0.3603,  ..., -0.1116,  0.3309,  0.1380],\n",
       "          [ 0.5645, -0.0059,  0.0320,  ...,  0.2352, -0.0505, -0.0771]],\n",
       "\n",
       "         [[ 0.0387, -0.1241,  0.1470,  ...,  0.0169,  0.0048, -0.1324],\n",
       "          [ 0.0721, -0.0773,  0.5199,  ...,  0.1248,  0.0303, -0.2344],\n",
       "          [-0.4161, -0.0423, -0.5174,  ..., -0.1377, -0.0967,  0.2065],\n",
       "          [-0.1816,  0.1154,  0.0127,  ...,  0.2168, -0.0582,  0.0226]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0807, -0.1906,  0.0639,  ..., -0.1490,  0.0250, -0.0507],\n",
       "          [-0.3579, -0.0472,  0.1095,  ...,  0.0663, -0.0370,  0.1475],\n",
       "          [-0.1359, -0.2010, -0.1008,  ...,  0.1834, -0.1976,  0.3971],\n",
       "          [-0.0813,  0.0977,  0.1992,  ...,  0.0237,  0.1389, -0.1172]],\n",
       "\n",
       "         [[ 0.1381, -0.1557, -0.2257,  ...,  0.1550,  0.0781, -0.2150],\n",
       "          [-0.2789, -0.2260,  0.2964,  ...,  0.2167,  0.0353,  0.1164],\n",
       "          [-0.2156,  0.0688, -0.1239,  ...,  0.2791,  0.0505, -0.1033],\n",
       "          [ 0.1219, -0.3069, -0.1184,  ..., -0.4852, -0.2602, -0.0402]],\n",
       "\n",
       "         [[-0.0571, -0.4920,  0.0953,  ...,  0.0823, -0.2186, -0.0627],\n",
       "          [ 0.1795, -0.0157, -0.1671,  ...,  0.2185,  0.4906,  0.0746],\n",
       "          [-0.0803, -0.0175, -0.0665,  ...,  0.1646,  0.0318,  0.0404],\n",
       "          [ 0.0378,  0.0898, -0.1854,  ...,  0.1708,  0.0623,  0.1845]]]])), (tensor([[[[-0.4429,  1.7014, -0.6907,  ...,  1.4862, -0.8501,  1.0029],\n",
       "          [ 1.3743,  0.8487, -0.6896,  ..., -0.0925, -1.4092, -0.0954],\n",
       "          [ 0.4908,  1.5732, -0.8540,  ...,  0.1579, -1.3239, -0.1936],\n",
       "          [-0.0671,  1.7162, -0.0697,  ..., -0.5293, -1.0193,  0.2869]],\n",
       "\n",
       "         [[-0.6637, -0.1895, -0.5674,  ..., -0.3815,  0.7412, -0.0891],\n",
       "          [-0.1669,  1.1982, -1.5149,  ..., -0.5160,  0.4696, -0.4340],\n",
       "          [-0.6952,  0.3425, -1.3999,  ..., -0.8975,  0.3990, -0.2001],\n",
       "          [-0.1838, -0.1106, -2.0887,  ..., -0.6172, -0.2309, -0.1275]],\n",
       "\n",
       "         [[ 0.5291, -0.0037, -0.2316,  ..., -1.2169,  0.2271, -0.3261],\n",
       "          [ 0.2644,  0.5442, -0.3083,  ..., -1.1646,  0.2780,  0.2626],\n",
       "          [-0.0581, -0.1167, -0.1463,  ..., -0.7505,  0.0270,  0.1683],\n",
       "          [ 0.0582, -0.0533, -0.5726,  ..., -0.7941,  0.1828,  0.6158]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3728, -0.6938, -0.4961,  ..., -0.5303,  1.0100, -0.6654],\n",
       "          [ 0.4357,  1.7161,  2.2183,  ...,  1.3373, -1.9016, -0.5297],\n",
       "          [-0.3894,  0.8506,  0.9698,  ..., -0.5584,  1.2113, -0.3954],\n",
       "          [-0.0570,  0.3863,  1.6058,  ...,  1.0281,  0.7014, -1.9016]],\n",
       "\n",
       "         [[-1.1796, -2.8647,  0.1567,  ...,  1.6974,  1.6059, -1.4394],\n",
       "          [ 0.2136,  1.0721, -0.4293,  ..., -1.0916,  0.5556, -0.0436],\n",
       "          [ 0.3315,  0.4285, -0.5034,  ..., -0.3555,  0.5274, -0.3263],\n",
       "          [-0.1077,  0.4432, -0.5612,  ..., -0.8353,  0.6431,  0.2116]],\n",
       "\n",
       "         [[ 1.4173,  1.6031,  1.6164,  ..., -0.2634, -0.1675,  0.3462],\n",
       "          [ 0.9477,  1.2226,  1.7770,  ...,  1.0936, -1.6220, -1.7104],\n",
       "          [ 0.6794,  2.4438,  0.7746,  ...,  0.7307, -1.2945,  0.6698],\n",
       "          [-0.1057,  2.5618,  2.4424,  ...,  1.2380, -0.4108, -0.5842]]]]), tensor([[[[ 0.4208, -0.0734,  0.3280,  ..., -0.0660,  0.2406,  0.2539],\n",
       "          [ 0.0094,  0.1840,  0.8090,  ..., -0.0764, -0.4035,  0.1018],\n",
       "          [-0.2642,  0.8336, -0.3297,  ...,  0.2345, -0.5374,  0.1320],\n",
       "          [ 0.7469, -0.3523, -0.5665,  ..., -0.2958,  0.2896, -0.0582]],\n",
       "\n",
       "         [[ 0.0056, -0.2284, -0.1241,  ...,  0.2776, -0.6636,  0.4794],\n",
       "          [ 0.1894, -0.1491,  0.2721,  ..., -0.5020,  0.4401,  0.5566],\n",
       "          [-0.0828,  0.3717,  0.5638,  ...,  0.2258,  0.9277,  0.4194],\n",
       "          [ 0.6166, -0.1770, -0.2956,  ..., -0.2849, -0.2718,  0.6026]],\n",
       "\n",
       "         [[ 0.0451, -0.1543, -0.4230,  ..., -0.6000,  0.0913,  0.0939],\n",
       "          [ 0.5417,  0.3104,  0.0171,  ..., -0.4946,  0.0339, -0.1924],\n",
       "          [ 0.4010,  0.0705,  0.0678,  ..., -0.7680, -0.0836,  0.0541],\n",
       "          [ 0.7981,  0.2307,  0.1953,  ..., -0.7680,  0.1165,  0.3457]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0882,  0.6416,  0.0576,  ...,  0.2420, -0.8808, -0.1153],\n",
       "          [-0.4200, -0.8640, -0.1090,  ..., -0.1935, -0.5571,  0.6112],\n",
       "          [ 0.0249,  0.2557,  0.2941,  ...,  0.2155, -0.3453, -0.1526],\n",
       "          [ 0.0601,  0.3544,  0.5788,  ...,  0.1667, -0.2305, -0.4238]],\n",
       "\n",
       "         [[ 0.1721, -0.2036, -0.1481,  ...,  0.4287, -3.3897, -0.0050],\n",
       "          [-0.1397,  0.1163,  0.0596,  ...,  0.5042, -0.0432, -0.3944],\n",
       "          [ 0.0721, -0.3476,  0.2416,  ..., -0.0895,  0.0357, -0.2450],\n",
       "          [-0.1097, -0.4021,  0.0159,  ...,  0.1344,  0.0763,  0.0909]],\n",
       "\n",
       "         [[ 0.1294, -0.0973, -0.0262,  ..., -0.3147,  0.1203, -0.1732],\n",
       "          [ 0.0250, -0.0217, -0.0245,  ..., -0.1267,  0.2678,  0.2072],\n",
       "          [ 0.0634,  0.1818, -0.1564,  ..., -0.2415,  0.3153,  0.2623],\n",
       "          [ 0.1822,  0.0348,  0.0813,  ..., -0.1996,  0.1029,  0.0907]]]])), (tensor([[[[-1.2485e-01, -1.0892e+00,  3.1150e-01,  ..., -6.5689e-01,\n",
       "           -1.6048e-01, -8.4813e-02],\n",
       "          [ 9.9339e-01, -2.0784e+00,  2.1353e-01,  ..., -3.4886e-01,\n",
       "           -5.7213e-01, -8.4121e-01],\n",
       "          [ 5.5756e-01, -1.6786e+00, -8.8744e-01,  ..., -1.8398e-01,\n",
       "            1.3680e-01, -4.5253e-01],\n",
       "          [ 7.7025e-01, -2.7345e+00, -1.2324e-01,  ..., -9.5965e-01,\n",
       "            1.6467e-01,  3.1356e-01]],\n",
       "\n",
       "         [[-4.0222e-01,  3.0196e-01, -3.2668e-01,  ...,  1.1396e+00,\n",
       "           -5.1263e-01, -5.1158e-01],\n",
       "          [-1.9662e+00, -8.3250e-01, -3.0089e-01,  ..., -7.8870e-02,\n",
       "            3.3094e-02,  2.2957e-01],\n",
       "          [-9.3393e-01, -1.4560e-01,  4.4689e-01,  ...,  2.3356e-02,\n",
       "            4.1780e-01,  1.5523e+00],\n",
       "          [ 2.8636e-03,  4.2808e-02, -1.6687e+00,  ...,  6.5722e-01,\n",
       "            5.4254e-01,  4.8895e-01]],\n",
       "\n",
       "         [[ 1.2923e+00,  2.9953e+00,  3.7112e+00,  ...,  6.8323e-01,\n",
       "            1.5592e+00, -6.8063e-01],\n",
       "          [-3.0753e+00,  1.8506e+00, -3.1876e+00,  ..., -1.9041e+00,\n",
       "            4.1159e+00,  3.4740e-01],\n",
       "          [-4.0096e+00,  8.4486e-01, -1.7629e+00,  ..., -3.3400e+00,\n",
       "            4.0366e+00,  4.6162e-02],\n",
       "          [-2.7569e+00,  1.4731e+00, -1.3038e+00,  ..., -2.3636e+00,\n",
       "            2.8505e+00,  1.2384e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3498e+00, -2.6675e+00, -2.7045e+00,  ...,  9.4501e-01,\n",
       "            3.9975e-01,  2.6751e+00],\n",
       "          [-1.2891e+00,  1.4442e+00,  3.6793e-01,  ...,  6.4334e-02,\n",
       "           -2.2165e+00,  4.3306e-01],\n",
       "          [-2.0947e+00,  9.6674e-01, -9.6556e-01,  ...,  3.8453e-01,\n",
       "           -3.2025e+00,  7.0452e-01],\n",
       "          [-3.1542e+00,  1.8005e+00,  9.3661e-01,  ..., -5.8836e-01,\n",
       "           -3.2547e+00, -3.5590e-01]],\n",
       "\n",
       "         [[ 1.6944e+00,  4.6650e-01,  8.9533e-01,  ..., -1.2667e-02,\n",
       "           -9.6927e-01, -3.2458e-01],\n",
       "          [ 1.7230e+00,  1.2067e+00,  1.2366e+00,  ...,  2.9018e-01,\n",
       "           -2.0735e+00, -1.4231e+00],\n",
       "          [ 1.7642e+00,  8.4785e-01,  8.2207e-01,  ...,  1.5403e-01,\n",
       "           -2.0370e+00, -1.4636e+00],\n",
       "          [ 2.5570e+00,  4.8490e-01,  1.1101e+00,  ...,  4.8406e-02,\n",
       "           -1.6614e+00, -1.3222e+00]],\n",
       "\n",
       "         [[-3.0077e-01,  1.0298e-01, -5.6940e-01,  ...,  2.3864e-01,\n",
       "            2.7998e-01,  1.8752e-01],\n",
       "          [ 2.2595e-01,  1.1171e-01, -3.0471e-01,  ..., -8.0950e-02,\n",
       "            5.6079e-01,  1.2503e-01],\n",
       "          [ 2.1247e-01,  1.1268e-01, -5.1350e-01,  ..., -3.3752e-01,\n",
       "           -1.0487e-01,  4.6240e-01],\n",
       "          [-8.4601e-01,  9.4520e-02, -6.2408e-01,  ..., -5.5758e-01,\n",
       "            9.6283e-01, -7.0620e-01]]]]), tensor([[[[-3.2901e-02, -1.0599e-02, -1.5212e-01,  ...,  1.8840e-02,\n",
       "            3.0390e-02, -5.8550e-01],\n",
       "          [ 1.0234e-01,  2.1928e-01, -3.7873e-01,  ..., -2.7679e-02,\n",
       "           -2.1757e-01,  6.5411e-01],\n",
       "          [ 5.3274e-01,  7.7841e-01,  6.1081e-02,  ..., -2.7596e-01,\n",
       "           -5.7730e-02,  7.4483e-01],\n",
       "          [ 1.8389e-01, -4.3621e-01,  4.8247e-01,  ...,  1.4029e-01,\n",
       "            9.1173e-01,  9.0925e-02]],\n",
       "\n",
       "         [[ 4.4920e-02, -4.7059e-02,  4.6090e-02,  ..., -8.3665e-03,\n",
       "           -3.0874e-02,  4.2419e-02],\n",
       "          [-4.8525e-02, -4.5327e-01, -5.5891e-02,  ...,  3.2361e-02,\n",
       "            4.5724e-01, -3.7040e-01],\n",
       "          [-3.5309e-02, -2.0263e-02,  1.5616e-01,  ...,  2.9811e-01,\n",
       "           -1.6055e-02,  2.5120e-02],\n",
       "          [ 1.5162e-01,  3.1311e-01,  5.5116e-02,  ...,  5.8466e-01,\n",
       "            1.2956e-01,  3.3648e-01]],\n",
       "\n",
       "         [[ 1.9610e-02, -7.3561e-01, -2.4084e-02,  ...,  4.3338e-02,\n",
       "           -2.4689e-02, -9.3788e-02],\n",
       "          [ 4.2577e-01, -6.4197e-01, -3.9757e-01,  ..., -1.4095e-01,\n",
       "            3.2730e-01,  7.3103e-01],\n",
       "          [-1.1381e-01, -1.5143e+00,  1.5325e-01,  ...,  2.3668e-01,\n",
       "           -8.2124e-02,  2.6318e-01],\n",
       "          [-3.7149e-01, -1.6965e+00,  4.8521e-02,  ...,  2.1276e-01,\n",
       "           -8.0953e-02,  2.8726e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.8478e-03, -6.8927e-02,  1.3137e+00,  ..., -7.7274e-02,\n",
       "            1.5943e-01, -1.5030e-02],\n",
       "          [-3.3545e-01, -1.6725e-01,  2.0547e+00,  ...,  3.6623e-01,\n",
       "            2.7014e-01,  3.6059e-01],\n",
       "          [ 3.5861e-01,  6.0658e-01,  2.3863e+00,  ...,  8.3569e-02,\n",
       "            4.2542e-01, -3.2851e-02],\n",
       "          [-4.3402e-01, -1.0479e-01,  1.4641e+00,  ...,  1.0414e-01,\n",
       "           -5.6815e-01,  1.4358e+00]],\n",
       "\n",
       "         [[ 1.2018e-02, -1.0588e-01, -2.3166e-01,  ...,  2.0130e-01,\n",
       "            1.0258e-01,  2.0048e-01],\n",
       "          [ 4.0419e-01, -3.0238e-01, -2.4694e-01,  ...,  7.0073e-01,\n",
       "           -7.7204e-01, -9.5100e-01],\n",
       "          [ 2.6653e-01, -2.3623e-01, -4.9750e-01,  ...,  1.4647e-01,\n",
       "            8.2767e-02, -1.1125e-01],\n",
       "          [ 1.4401e-01, -3.1624e-01, -4.4873e-01,  ...,  3.4521e-01,\n",
       "           -6.5832e-02, -6.2205e-02]],\n",
       "\n",
       "         [[ 1.3444e-02,  1.9561e-03, -8.2095e-03,  ...,  1.6904e-02,\n",
       "            2.2943e-01,  2.2110e-02],\n",
       "          [-4.1483e-01,  3.5416e-01,  3.1881e-01,  ..., -4.5279e-01,\n",
       "           -1.8346e+00,  5.0146e-01],\n",
       "          [ 2.1478e-01, -6.9608e-01, -3.4734e-02,  ..., -2.3527e-01,\n",
       "           -2.0510e+00, -4.3463e-02],\n",
       "          [-1.5012e-01, -2.1772e-01, -4.7559e-01,  ...,  9.5937e-02,\n",
       "           -2.1398e+00,  4.0356e-01]]]])), (tensor([[[[ 0.0424, -0.2118,  0.1637,  ..., -0.8727,  0.7107, -1.1590],\n",
       "          [-0.0249, -0.6443,  0.5457,  ..., -0.6798, -1.3948,  0.2796],\n",
       "          [-1.0824,  0.6305, -0.7293,  ..., -0.9685, -1.3432,  0.5087],\n",
       "          [-0.9922, -0.5166, -0.2735,  ...,  0.5085, -0.5633,  1.8717]],\n",
       "\n",
       "         [[ 0.8196,  0.1935,  0.0242,  ..., -0.1545, -1.0530, -0.1750],\n",
       "          [ 0.0335, -1.2800,  1.6604,  ...,  1.2608,  5.4236,  2.1315],\n",
       "          [ 0.4848, -0.7511, -0.1953,  ...,  0.9773,  6.3051,  1.3952],\n",
       "          [-0.1116, -1.1854, -0.5760,  ...,  0.3903,  5.5737,  2.8476]],\n",
       "\n",
       "         [[ 0.3653, -0.3572, -0.3316,  ...,  0.3246,  1.4386,  0.2710],\n",
       "          [-0.0327, -6.7977, -1.3213,  ..., -1.6673, -1.5678, -5.1224],\n",
       "          [-0.4243, -6.3550, -1.2516,  ..., -2.4256, -3.0643, -5.7382],\n",
       "          [ 0.0710, -6.7749, -0.9766,  ..., -2.8864, -3.5688, -4.7724]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1842,  1.7963,  0.5499,  ...,  0.2605,  0.4402, -1.6889],\n",
       "          [-3.2688, -4.4593,  1.4404,  ..., -3.0561,  0.4428,  5.0847],\n",
       "          [-1.6684, -5.7961,  0.7947,  ..., -2.6741, -1.4566,  6.3513],\n",
       "          [-0.4103, -4.8701,  1.1112,  ..., -2.2014, -1.8221,  6.2139]],\n",
       "\n",
       "         [[ 0.0729, -0.0484,  0.1504,  ..., -0.0845, -0.0967, -0.1594],\n",
       "          [-1.0279, -1.2041,  0.3492,  ..., -1.7430, -0.1890, -0.2538],\n",
       "          [ 0.0592, -1.8867, -0.6904,  ..., -0.0956,  0.3735, -0.8848],\n",
       "          [ 0.7395, -0.0276, -0.7268,  ..., -1.5075, -0.5571, -0.2546]],\n",
       "\n",
       "         [[ 0.4092, -0.0809,  1.8731,  ..., -0.1971, -0.2098, -0.9803],\n",
       "          [ 2.7040,  1.1317, -2.1446,  ...,  2.5664,  1.2632,  3.1897],\n",
       "          [ 2.4635,  0.6500, -2.3374,  ...,  0.5308,  2.3066,  3.0190],\n",
       "          [ 2.9176,  1.5837, -2.2797,  ...,  1.2287,  0.1092,  4.7710]]]]), tensor([[[[ 6.9679e-02,  5.4387e-02, -9.5587e-03,  ...,  2.8532e-03,\n",
       "            9.0584e-02,  1.4572e-02],\n",
       "          [-5.5154e-02, -6.2483e-02,  6.0821e-02,  ..., -9.6772e-02,\n",
       "           -2.5729e-01, -1.3261e+00],\n",
       "          [-3.4933e-03, -4.5896e-04, -4.2207e-01,  ...,  6.1325e-02,\n",
       "           -3.6534e-01, -3.5158e-01],\n",
       "          [-3.5441e-02,  7.9168e-02, -5.7604e-01,  ..., -3.7580e-01,\n",
       "           -6.3908e-01, -8.1367e-01]],\n",
       "\n",
       "         [[-4.1726e-02, -9.6663e-03,  9.1851e-02,  ..., -5.0178e-02,\n",
       "           -3.1655e-02, -4.6744e-02],\n",
       "          [ 3.2710e-02, -5.9486e-01,  8.1254e-01,  ..., -2.6009e-01,\n",
       "           -6.8992e-02,  2.0970e-01],\n",
       "          [-1.5799e-01, -1.8575e-01,  1.1244e-01,  ...,  1.9757e-01,\n",
       "            5.7258e-02,  1.5232e-01],\n",
       "          [-5.6733e-01, -8.6542e-03, -5.7176e-01,  ...,  5.0830e-01,\n",
       "            4.9320e-01,  7.4142e-03]],\n",
       "\n",
       "         [[ 4.2130e-02, -1.1605e-01, -6.5851e-02,  ..., -2.2535e-02,\n",
       "            9.7068e-02, -1.5661e-01],\n",
       "          [-9.2442e-01, -8.7217e-02, -1.3878e-01,  ..., -5.6805e-01,\n",
       "           -1.1631e-01,  1.5537e-01],\n",
       "          [-2.9951e-01,  2.2818e-01,  1.4375e+00,  ...,  5.8889e-02,\n",
       "            1.5296e-01,  5.2132e-02],\n",
       "          [-2.0230e-02, -3.6619e-01, -1.0021e-01,  ..., -8.2534e-02,\n",
       "           -2.8163e-01, -4.8605e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2474e-02,  1.2862e-01, -9.2766e-03,  ..., -1.4543e-02,\n",
       "            6.2499e-02, -5.1551e-02],\n",
       "          [ 4.4181e-01, -2.9042e-01, -1.8738e-01,  ...,  1.3377e-01,\n",
       "           -3.3589e-01,  7.2926e-01],\n",
       "          [-2.8292e-01,  1.0259e-01, -1.2240e-01,  ...,  1.4179e-01,\n",
       "            1.7680e-01,  1.1006e-01],\n",
       "          [-3.5553e-01, -8.1312e-02,  6.3898e-01,  ..., -1.2570e-03,\n",
       "           -5.8799e-01, -4.5112e-01]],\n",
       "\n",
       "         [[-2.0118e-01, -1.2091e-01, -5.5330e-02,  ..., -2.5183e-01,\n",
       "           -1.5058e-02, -5.9715e-02],\n",
       "          [-1.1753e+00, -4.0308e-01,  5.4829e-01,  ...,  6.2824e-01,\n",
       "            1.1999e-01,  6.1103e-01],\n",
       "          [-3.5791e-01, -2.1055e-01,  4.0812e-01,  ...,  5.2716e-02,\n",
       "            3.9615e-01,  2.3834e-01],\n",
       "          [-1.2685e-01, -8.1207e-01,  1.1086e+00,  ...,  4.0498e-01,\n",
       "            9.3048e-01,  3.6843e-01]],\n",
       "\n",
       "         [[ 1.0480e-01, -6.9615e-02, -3.3840e-02,  ..., -2.0428e-02,\n",
       "           -9.2801e-02, -9.3236e-02],\n",
       "          [-4.9912e-01,  2.3250e-02,  2.2643e-01,  ...,  1.8760e-01,\n",
       "           -1.6172e-01,  8.4068e-02],\n",
       "          [-8.8755e-02, -1.2174e-01, -1.7043e+00,  ..., -3.7368e-02,\n",
       "           -2.9978e-01,  9.5211e-02],\n",
       "          [-8.9905e-02,  9.2714e-02, -2.3660e-01,  ..., -2.1381e-01,\n",
       "           -4.9139e-01, -3.1257e-01]]]])), (tensor([[[[-8.7833e-01, -1.4351e-01,  3.3771e-01,  ..., -9.8041e-01,\n",
       "            7.1755e-03, -2.9582e+00],\n",
       "          [ 2.3520e+00,  6.8682e-02, -2.5685e+00,  ..., -1.7427e+00,\n",
       "           -4.4684e+00,  7.1657e+00],\n",
       "          [ 1.5798e+00,  2.0696e-01, -1.0892e+00,  ..., -2.5542e+00,\n",
       "           -3.1300e+00,  7.6613e+00],\n",
       "          [ 1.4371e+00,  4.9585e-01, -2.8272e+00,  ..., -1.6869e+00,\n",
       "           -3.2063e+00,  7.4440e+00]],\n",
       "\n",
       "         [[ 3.7145e-01, -6.6517e-02,  4.7564e-01,  ..., -1.2530e-01,\n",
       "           -7.1409e-02, -2.2188e+00],\n",
       "          [-2.8965e+00, -3.9932e-01,  1.9095e+00,  ..., -1.1140e-01,\n",
       "           -1.3475e+00,  7.0748e+00],\n",
       "          [-2.1615e+00, -1.1604e+00,  2.6257e+00,  ..., -7.8631e-01,\n",
       "           -4.3699e-01,  6.2675e+00],\n",
       "          [-2.8680e+00, -1.6562e+00,  3.6304e+00,  ...,  9.0197e-01,\n",
       "           -1.7258e+00,  7.2830e+00]],\n",
       "\n",
       "         [[ 1.5120e-01, -6.6201e-01, -2.4131e-01,  ...,  1.4116e-01,\n",
       "            2.6647e-01, -1.9205e-01],\n",
       "          [-1.2037e-01,  2.0550e+00,  5.5844e-01,  ..., -7.8678e-01,\n",
       "           -2.8988e-01,  3.7795e-01],\n",
       "          [-1.5585e+00,  2.7598e+00,  1.2137e+00,  ...,  4.7167e-01,\n",
       "            4.0728e-01,  6.6083e-01],\n",
       "          [-2.3316e-01,  2.8031e+00, -9.7414e-02,  ..., -1.9274e-01,\n",
       "            3.5797e-01,  3.8093e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.6169e-01,  3.5874e-02, -1.4116e-02,  ...,  1.2779e+00,\n",
       "            5.3801e-02,  1.7804e+00],\n",
       "          [ 1.0151e+00, -4.2919e-01, -1.5432e+00,  ..., -2.8194e+00,\n",
       "           -1.7330e+00, -7.2798e-01],\n",
       "          [-1.1882e-01, -5.0312e-01,  5.8254e-02,  ..., -2.8543e+00,\n",
       "           -2.5628e-01, -1.5441e+00],\n",
       "          [ 7.8049e-01, -3.2062e-01, -1.7466e+00,  ..., -2.2239e+00,\n",
       "           -1.2959e+00, -1.4710e+00]],\n",
       "\n",
       "         [[-3.0994e-01, -1.5448e-01,  2.1987e-01,  ...,  2.6219e-01,\n",
       "           -2.0387e-02,  1.5249e-02],\n",
       "          [-3.8072e-01, -2.0132e+00,  4.9234e-01,  ...,  9.0214e-01,\n",
       "           -6.6170e-02, -6.0389e-01],\n",
       "          [ 3.7344e-02, -5.2860e-01,  1.1190e-02,  ...,  9.2150e-01,\n",
       "            4.0561e-02,  6.0367e-01],\n",
       "          [-3.0341e-01, -6.2755e-01,  1.1517e+00,  ...,  1.2191e+00,\n",
       "            1.3458e+00,  7.6806e-01]],\n",
       "\n",
       "         [[ 3.4223e+00,  2.1566e+00, -2.1395e+00,  ..., -2.9103e+00,\n",
       "           -3.8977e+00, -1.2195e+00],\n",
       "          [-1.3007e+00,  1.3584e+00,  3.7364e+00,  ..., -1.8891e+00,\n",
       "            7.2931e+00,  1.6671e-01],\n",
       "          [-2.9693e+00,  1.4552e+00,  1.9036e+00,  ..., -4.9846e+00,\n",
       "            1.1498e+01,  1.7359e+00],\n",
       "          [-3.2126e+00,  5.1778e-01,  4.3842e+00,  ..., -2.6957e+00,\n",
       "            1.2507e+01, -2.8269e+00]]]]), tensor([[[[ 0.0149, -0.0634,  0.0186,  ...,  0.0664,  0.0262,  0.0709],\n",
       "          [ 0.0662, -0.3723, -0.0505,  ...,  0.3580,  0.3120, -0.2215],\n",
       "          [ 0.2177, -0.1625,  0.1564,  ...,  0.2310,  0.3242,  0.0270],\n",
       "          [ 0.4170, -0.3658, -0.0556,  ...,  0.1195, -0.3138, -0.5971]],\n",
       "\n",
       "         [[-0.0460, -0.0201, -0.1492,  ..., -0.0348,  0.0461, -0.0198],\n",
       "          [ 0.5117,  0.2246, -0.3263,  ...,  0.3184,  0.5067, -0.2845],\n",
       "          [-0.6494,  0.1465, -0.0656,  ...,  0.2973, -0.2200,  0.0334],\n",
       "          [ 0.2608, -0.0966,  0.2308,  ...,  0.7369, -0.7308, -0.2600]],\n",
       "\n",
       "         [[ 0.0451,  0.0682,  0.0886,  ...,  0.0113, -0.0792,  0.0128],\n",
       "          [-0.6614, -0.5431, -0.5666,  ...,  0.8854, -1.8533,  0.9074],\n",
       "          [-0.9796,  0.3631, -0.4148,  ..., -0.2955, -0.5118,  0.0544],\n",
       "          [-1.3308, -0.3328,  0.8218,  ...,  0.8782,  0.0493, -0.1261]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0022,  0.0662, -0.0824,  ...,  0.0480,  0.0390, -0.1217],\n",
       "          [ 0.8051, -0.7638,  0.5854,  ..., -0.1230,  0.0445,  0.3154],\n",
       "          [ 0.3129, -0.6428,  0.0365,  ...,  0.1439,  0.4628, -0.0223],\n",
       "          [-0.2057, -0.3894,  0.4267,  ..., -0.0875, -0.2746,  0.7100]],\n",
       "\n",
       "         [[-0.1460, -0.0433,  0.0971,  ..., -0.0479,  0.0481, -0.0131],\n",
       "          [ 0.8686,  0.5858, -0.5667,  ...,  0.6166, -1.7788,  0.8849],\n",
       "          [ 0.1854,  0.1395,  0.2193,  ..., -0.0185,  0.0144,  0.1103],\n",
       "          [ 0.9178, -0.0793, -0.9049,  ...,  0.7952, -0.0744, -0.9031]],\n",
       "\n",
       "         [[-0.0318, -0.0190, -0.0191,  ..., -0.0276,  0.0126, -0.0188],\n",
       "          [-0.7899, -0.2687, -0.0675,  ..., -0.4190, -0.6408, -0.6485],\n",
       "          [-0.2158, -0.1843, -0.1983,  ..., -0.4338, -0.4812, -0.2530],\n",
       "          [-0.6240, -1.2451,  0.4375,  ..., -0.8118,  0.2128,  0.2129]]]])), (tensor([[[[ 3.8184e-02, -2.7758e-01,  2.3279e-01,  ...,  1.6788e+00,\n",
       "           -2.2682e-01, -5.1015e-02],\n",
       "          [ 5.2208e-01,  8.1778e-02,  8.9769e-01,  ..., -2.5026e+00,\n",
       "           -8.3921e-01, -2.0073e+00],\n",
       "          [ 1.5046e-01,  1.1006e-01, -8.5704e-01,  ..., -1.3623e+00,\n",
       "           -1.0934e-01, -1.9302e+00],\n",
       "          [-5.7107e-01,  9.0743e-01, -6.4183e-01,  ..., -3.1398e+00,\n",
       "            5.4699e-01, -1.3780e+00]],\n",
       "\n",
       "         [[ 1.5066e-01,  9.8471e-01, -1.3762e+00,  ..., -1.3977e-01,\n",
       "            2.5742e-01,  9.2433e-01],\n",
       "          [-3.1968e+00, -5.5919e+00,  3.9208e-01,  ..., -8.6266e-01,\n",
       "           -2.8264e-01, -3.2688e+00],\n",
       "          [-2.8037e+00, -4.0835e+00,  3.2466e-01,  ..., -9.6265e-01,\n",
       "           -4.0823e-01, -2.5227e+00],\n",
       "          [-3.1024e+00, -4.0890e+00,  1.7717e+00,  ..., -1.3810e+00,\n",
       "           -8.6046e-01, -1.7650e+00]],\n",
       "\n",
       "         [[-6.8333e-01,  2.1993e-01, -4.7749e-02,  ...,  1.8999e-01,\n",
       "            2.3304e-02, -2.8594e-01],\n",
       "          [ 1.0397e+00, -3.4136e-01, -6.2067e-01,  ...,  1.8265e-01,\n",
       "            1.6563e-01,  7.2814e-03],\n",
       "          [ 1.9483e+00,  4.7366e-01,  7.3723e-01,  ...,  4.1182e-01,\n",
       "           -7.0309e-02, -8.4996e-01],\n",
       "          [ 2.1805e+00,  1.0315e-01, -1.7709e+00,  ..., -1.0169e+00,\n",
       "            2.0528e+00, -2.9059e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.3685e-02,  1.0540e-01,  1.2027e-01,  ..., -1.0576e-01,\n",
       "            2.1114e-02,  1.3050e-01],\n",
       "          [ 3.6456e-01,  5.1807e-01,  2.1313e-01,  ...,  1.3970e+00,\n",
       "           -3.9980e-01, -2.2791e-01],\n",
       "          [-2.0203e-01,  8.4088e-01,  6.4627e-01,  ...,  1.0115e+00,\n",
       "            3.3307e-01, -7.0844e-02],\n",
       "          [ 5.4139e-01, -4.2985e-01, -8.1102e-01,  ...,  1.2129e+00,\n",
       "            2.1628e-01,  9.4657e-01]],\n",
       "\n",
       "         [[-2.9556e+00,  3.8597e-01, -2.1885e-02,  ..., -4.4353e-01,\n",
       "           -3.3137e-01,  1.2129e+00],\n",
       "          [ 5.9931e+00, -4.4243e-02, -1.0741e+00,  ..., -6.4186e-01,\n",
       "            7.4279e-01, -1.7485e+00],\n",
       "          [ 5.6837e+00,  9.2747e-01, -1.7991e+00,  ..., -9.3537e-01,\n",
       "            2.9894e-01, -8.5594e-01],\n",
       "          [ 6.2911e+00,  1.4834e+00, -7.2681e-01,  ...,  5.3802e-01,\n",
       "           -3.9400e-01, -1.8418e+00]],\n",
       "\n",
       "         [[-5.9147e-03, -2.2829e-01,  2.3931e-02,  ..., -1.3441e-01,\n",
       "            3.2670e-01,  7.5771e-02],\n",
       "          [ 6.2397e-01, -2.0572e+00, -3.2521e-01,  ...,  3.0855e-01,\n",
       "            1.1809e+00, -9.3743e-01],\n",
       "          [-6.5761e-02, -1.6696e+00,  1.7004e+00,  ...,  8.3492e-01,\n",
       "            8.3878e-01, -1.5128e+00],\n",
       "          [-2.3924e-01, -5.1347e-01,  5.3670e-01,  ..., -7.6145e-03,\n",
       "            1.4380e+00, -6.8514e-03]]]]), tensor([[[[-1.9347e-02, -3.3054e-02, -3.4045e-03,  ..., -2.8687e-02,\n",
       "           -2.6482e-02,  3.5637e-01],\n",
       "          [ 1.6041e+00,  2.4773e-01, -3.7754e-01,  ..., -1.7874e-01,\n",
       "            7.1671e-01, -6.0155e-01],\n",
       "          [ 1.1132e+00, -4.9048e-01, -7.2750e-01,  ..., -5.4028e-01,\n",
       "            7.7690e-01, -5.4762e-01],\n",
       "          [-4.2405e-01,  4.4630e-01,  2.2637e-01,  ...,  6.2571e-01,\n",
       "            3.7057e-01, -8.7105e-01]],\n",
       "\n",
       "         [[ 6.1771e-03, -1.2940e-02,  2.5237e-03,  ..., -1.8164e-02,\n",
       "            1.9611e-02,  5.0732e-03],\n",
       "          [-3.2934e-01, -4.3853e-01,  1.0256e-02,  ...,  6.9887e-01,\n",
       "            1.9605e+00, -5.4963e-01],\n",
       "          [ 8.5620e-01, -8.5075e-02, -5.7184e-01,  ...,  6.2997e-01,\n",
       "            1.8136e+00,  2.0656e-01],\n",
       "          [ 9.5183e-01, -7.2811e-01,  6.5293e-01,  ..., -8.4825e-01,\n",
       "            1.1850e+00, -2.1867e-01]],\n",
       "\n",
       "         [[-7.7717e-02, -6.3292e-03, -4.1906e-02,  ..., -4.9341e-02,\n",
       "           -6.1695e-03, -7.1842e-02],\n",
       "          [-1.3337e+00, -4.2000e-01, -2.6836e-01,  ..., -5.1189e-01,\n",
       "           -1.9436e-01,  1.1735e+00],\n",
       "          [-6.8706e-01,  8.8204e-01,  6.4519e-01,  ..., -1.6930e-01,\n",
       "            1.1163e+00,  7.0525e-02],\n",
       "          [-7.1022e-01,  1.3451e-01,  5.5795e-01,  ..., -3.1487e-01,\n",
       "            3.3580e-01,  1.0486e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4383e-01, -1.7403e-01, -4.3918e-02,  ..., -4.9052e-01,\n",
       "            2.0137e-01,  8.6015e-02],\n",
       "          [-1.9360e-01, -1.5164e+00,  1.2331e+00,  ...,  1.9213e-01,\n",
       "           -1.0418e+00, -6.2363e-01],\n",
       "          [-1.0357e+00, -1.1312e+00,  3.0434e-01,  ...,  1.0710e+00,\n",
       "            4.7807e-01, -1.2871e+00],\n",
       "          [ 9.4290e-01, -2.5626e+00,  1.1855e+00,  ...,  1.7048e+00,\n",
       "            1.3440e-01, -8.6009e-03]],\n",
       "\n",
       "         [[-1.0098e-01, -1.3770e-01, -3.3733e-02,  ..., -1.9181e-01,\n",
       "           -1.6040e-01,  1.2220e-01],\n",
       "          [-6.3404e-01, -3.7809e-01, -2.1832e-01,  ..., -1.3135e+00,\n",
       "           -7.2051e-01, -5.4653e-01],\n",
       "          [ 5.1838e-03,  3.1286e-01, -6.6970e-02,  ..., -6.7096e-01,\n",
       "           -5.7598e-01,  3.0651e-01],\n",
       "          [ 2.4645e-01,  3.4342e-01,  3.4776e-01,  ..., -1.8551e-01,\n",
       "            1.0218e+00, -7.4981e-01]],\n",
       "\n",
       "         [[-6.5261e-03, -3.2608e-02,  1.1558e-01,  ...,  7.0247e-02,\n",
       "           -3.8239e-02,  2.2076e-03],\n",
       "          [ 4.3749e-01, -2.7750e-01, -6.4217e-01,  ...,  5.4250e-01,\n",
       "           -3.1752e-01, -3.4111e-01],\n",
       "          [ 3.3571e-01, -5.3948e-01, -9.8377e-01,  ..., -7.3787e-02,\n",
       "           -1.5356e-01,  2.7658e-01],\n",
       "          [ 1.1010e+00,  9.9487e-01,  4.3941e-02,  ...,  1.3681e+00,\n",
       "           -8.5430e-01,  6.6795e-01]]]])), (tensor([[[[-0.3570,  0.8688, -0.1448,  ...,  1.1097, -0.1340,  0.1300],\n",
       "          [-0.9821, -4.3271,  0.4120,  ..., -4.7474,  0.6519,  1.5478],\n",
       "          [-0.5462, -4.5694,  0.5748,  ..., -3.4452,  1.5557,  1.4300],\n",
       "          [-0.1853, -4.8494,  1.0277,  ..., -4.4865,  2.9870,  1.6851]],\n",
       "\n",
       "         [[ 0.0317,  0.8753, -0.6492,  ..., -0.0115,  0.3128,  0.0190],\n",
       "          [ 2.2832, -0.1133, -0.1561,  ...,  1.2742, -0.7333,  0.2684],\n",
       "          [ 0.0547,  0.5661, -1.4023,  ...,  2.2613, -0.3445, -0.0260],\n",
       "          [-0.1548,  0.6025, -0.0506,  ...,  3.3391, -0.3488,  0.8766]],\n",
       "\n",
       "         [[-0.2899,  0.1247, -1.0118,  ..., -0.3547, -0.0646, -0.1312],\n",
       "          [ 0.1155,  0.2941,  3.0989,  ...,  0.8264,  0.6604, -0.4747],\n",
       "          [-0.4729, -1.1494,  2.3322,  ..., -0.2391, -0.6485,  0.6455],\n",
       "          [ 0.5424, -0.5403,  2.8659,  ...,  0.3129,  0.6245,  0.0785]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3589,  0.0815, -0.0816,  ..., -0.0387,  0.2325, -0.0136],\n",
       "          [ 0.5626,  1.0089,  2.9107,  ..., -0.4463,  0.9277, -0.1219],\n",
       "          [ 1.0142, -0.5226,  0.9333,  ...,  0.0231,  1.5161,  0.6072],\n",
       "          [-0.8166,  0.0772,  0.2547,  ..., -0.7334,  2.5921, -0.0123]],\n",
       "\n",
       "         [[ 0.1910,  0.0733,  0.3313,  ...,  0.4052,  0.0090,  0.2337],\n",
       "          [ 0.7779,  0.8471,  0.9251,  ..., -1.0888,  0.1620,  1.1875],\n",
       "          [-0.3020,  1.1992,  1.2683,  ..., -1.1532,  2.1028,  0.2942],\n",
       "          [ 1.1801,  1.2563,  0.1440,  ..., -0.7949, -0.4799,  0.1261]],\n",
       "\n",
       "         [[-3.0409,  0.5513,  0.5901,  ..., -0.9390,  0.3411,  0.1802],\n",
       "          [ 7.2238, -1.2404,  0.2371,  ...,  1.2331, -0.3301,  0.2718],\n",
       "          [ 8.8131, -2.0429, -0.9616,  ...,  1.4864, -0.8229,  1.6084],\n",
       "          [ 8.8703, -2.0371, -1.8507,  ...,  1.4985, -2.0684, -1.0454]]]]), tensor([[[[ 3.2242e-02, -5.8045e-02,  2.5008e-02,  ..., -5.4749e-02,\n",
       "           -2.6752e-03, -8.8158e-02],\n",
       "          [-9.2663e-01, -2.5625e-03, -5.3188e-01,  ...,  1.2785e-02,\n",
       "            1.4955e-01, -7.1393e-01],\n",
       "          [-3.3491e-01, -6.8396e-01,  2.9188e-01,  ..., -2.6565e-02,\n",
       "           -8.6347e-02, -5.4265e-01],\n",
       "          [ 4.3760e-01, -3.4044e-01, -7.4988e-01,  ...,  1.1848e-01,\n",
       "            9.0896e-01,  1.8556e-01]],\n",
       "\n",
       "         [[ 7.8940e-02,  1.2261e-02, -1.6185e-02,  ..., -2.9235e-02,\n",
       "           -1.2771e-02, -2.2784e-02],\n",
       "          [-3.0239e-01,  4.3858e-01,  2.4056e-01,  ..., -7.8460e-01,\n",
       "           -1.5709e+00, -1.0676e+00],\n",
       "          [-1.2940e-01,  6.3239e-01, -2.0779e-01,  ..., -6.3873e-01,\n",
       "           -1.1738e+00, -1.6551e-03],\n",
       "          [-1.6975e+00,  8.4287e-01,  8.1175e-01,  ..., -1.4527e+00,\n",
       "           -2.3012e-01, -9.9640e-01]],\n",
       "\n",
       "         [[ 5.6835e-02,  1.2338e-02, -2.1545e-02,  ...,  1.0054e-02,\n",
       "           -3.9785e-02, -5.9249e-02],\n",
       "          [ 7.2388e-01,  1.5526e-01,  8.9488e-01,  ..., -1.5755e+00,\n",
       "            8.2087e-01,  3.4273e-01],\n",
       "          [ 5.7302e-01, -1.5471e+00, -1.9338e-01,  ...,  1.0895e-01,\n",
       "           -2.2874e-01,  1.1917e+00],\n",
       "          [-1.6614e-01, -8.5512e-01,  2.2806e-01,  ..., -4.5840e-01,\n",
       "            9.3683e-01,  1.7146e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.0521e-03,  1.5049e-02,  7.1201e-03,  ..., -4.5748e-02,\n",
       "           -1.2840e-02,  2.6904e-02],\n",
       "          [-2.0497e+00, -1.6723e-01, -4.5428e-01,  ...,  1.5079e+00,\n",
       "            1.7904e-01,  2.9771e-01],\n",
       "          [-5.6927e-01, -9.1605e-01, -4.4023e-01,  ...,  1.3711e+00,\n",
       "           -2.2109e+00, -3.8787e-01],\n",
       "          [-6.3251e-01,  4.2156e-01,  1.6105e-01,  ...,  1.0066e+00,\n",
       "            8.4073e-02, -6.7040e-01]],\n",
       "\n",
       "         [[ 5.6713e-02, -3.0614e-02,  1.9770e-02,  ...,  3.1651e-02,\n",
       "           -1.1575e-02, -2.9566e-02],\n",
       "          [ 1.9442e-01,  1.8814e-01, -6.8498e-01,  ..., -1.3147e+00,\n",
       "           -7.2503e-01,  5.2997e-01],\n",
       "          [ 2.0708e-01,  1.8685e-01, -1.8137e-01,  ..., -8.1234e-01,\n",
       "           -5.2567e-01,  4.3959e-01],\n",
       "          [ 1.4394e-01,  4.9669e-01, -8.6662e-01,  ..., -1.9575e+00,\n",
       "           -6.3572e-01,  1.2591e+00]],\n",
       "\n",
       "         [[ 5.8978e-02, -2.1208e-01, -6.3512e-02,  ..., -2.0376e-02,\n",
       "            1.7842e-01, -6.6979e-02],\n",
       "          [-6.3145e-01, -5.9407e-01, -7.8469e-01,  ...,  4.8716e-01,\n",
       "            3.7049e-01, -2.4681e-01],\n",
       "          [-2.7077e-01, -8.9888e-03,  5.4499e-01,  ...,  3.3318e-01,\n",
       "            2.5388e-01, -1.7122e-01],\n",
       "          [ 3.2944e-01,  1.0185e+00, -8.9987e-02,  ...,  2.2999e-01,\n",
       "           -7.6856e-01,  3.6528e-02]]]])), (tensor([[[[ 1.0373, -0.2840, -0.1196,  ...,  0.6211,  0.6819, -0.3341],\n",
       "          [-5.8434, -3.2663,  0.7723,  ..., -0.3567, -5.5373, -1.8401],\n",
       "          [-5.3169, -2.6061, -0.4581,  ...,  0.3113, -5.4674, -1.3297],\n",
       "          [-6.7351, -2.0236, -0.5375,  ...,  0.3513, -5.1388,  0.1089]],\n",
       "\n",
       "         [[-0.1165, -0.0795,  0.1708,  ..., -0.0160, -0.8566, -0.1703],\n",
       "          [ 1.0090,  0.8170,  0.1307,  ...,  0.9530,  0.2668,  1.1346],\n",
       "          [ 1.4035,  0.1231,  0.0496,  ...,  0.9251, -0.4585,  1.2806],\n",
       "          [ 1.2951,  0.5333, -0.5292,  ...,  0.1264,  0.8428,  1.2362]],\n",
       "\n",
       "         [[ 0.1869,  0.2958,  1.0970,  ..., -0.4583,  0.4665, -0.5066],\n",
       "          [-0.2456, -1.8784, -2.3594,  ..., -1.0826, -2.7805,  0.5181],\n",
       "          [-1.2572, -1.5905, -3.7217,  ..., -0.3628, -2.9421,  2.8222],\n",
       "          [-1.0618, -0.4450, -1.3943,  ..., -0.2053, -2.3539,  2.6536]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1474,  0.0676, -0.2094,  ...,  0.0522,  0.1646,  0.0401],\n",
       "          [-0.0447, -0.5385,  1.2884,  ...,  0.7592,  0.9175,  0.4616],\n",
       "          [-0.1373, -0.0647,  0.0590,  ...,  1.7011,  1.1588, -0.0143],\n",
       "          [ 0.8463, -0.3261, -0.2692,  ..., -0.1394,  0.1538,  0.0655]],\n",
       "\n",
       "         [[-0.3383, -2.1841,  0.1423,  ..., -0.0544, -0.0264,  0.9122],\n",
       "          [-0.4719,  1.6770, -0.9816,  ...,  2.0015, -1.3383,  0.1975],\n",
       "          [-1.1078,  2.8044, -0.4069,  ...,  0.3785, -1.1532,  0.9043],\n",
       "          [-0.1335,  1.8071,  0.8397,  ...,  0.7087, -0.8959,  1.8794]],\n",
       "\n",
       "         [[ 0.3633,  0.0771, -0.1473,  ...,  0.6508,  0.1428,  0.2661],\n",
       "          [-1.0805, -1.4298,  0.4953,  ..., -0.1399,  0.2109, -0.3243],\n",
       "          [-1.2403, -1.2030, -0.0998,  ..., -0.2580,  0.3014,  0.1404],\n",
       "          [-1.5192, -0.9732,  0.7389,  ..., -0.3118,  1.3279,  0.8664]]]]), tensor([[[[-0.0102,  0.0311, -0.0569,  ..., -0.0167, -0.0124,  0.0283],\n",
       "          [ 1.4799, -1.2771,  0.4499,  ...,  0.5994, -1.1337, -0.3985],\n",
       "          [ 0.9354, -1.5552, -0.1755,  ...,  0.1079, -0.2401, -1.5388],\n",
       "          [-0.0392, -1.6362, -0.5493,  ..., -0.1305,  0.2476,  0.8935]],\n",
       "\n",
       "         [[ 0.0282, -0.0349,  0.0444,  ...,  0.0505, -0.0420, -0.0038],\n",
       "          [-0.1710,  0.4048,  0.0211,  ...,  1.1394, -2.0726, -0.2761],\n",
       "          [ 1.0316, -0.0260,  0.0084,  ...,  0.2190, -0.6003, -0.0192],\n",
       "          [ 0.3259, -0.3642,  0.0669,  ...,  0.7739, -1.6022, -1.7112]],\n",
       "\n",
       "         [[ 0.0288,  0.0057,  0.0763,  ...,  0.0476, -0.0389,  0.0275],\n",
       "          [ 0.4091,  1.6341, -0.1274,  ...,  2.6997, -0.3446,  0.7923],\n",
       "          [-0.4032,  0.1783,  0.8845,  ...,  1.3867,  0.3938,  1.4801],\n",
       "          [-0.5278,  1.2259, -0.8369,  ...,  0.0305, -0.5831,  0.0594]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1739,  0.0741,  0.0826,  ...,  0.0464,  0.0390, -0.1332],\n",
       "          [ 1.0649,  0.7370,  0.8092,  ...,  0.2070, -1.9223, -0.5296],\n",
       "          [-0.0974,  0.5891,  0.1577,  ...,  0.5068, -1.2901, -1.3977],\n",
       "          [ 0.6040, -0.2010,  0.1913,  ...,  1.2024, -0.6489, -1.7015]],\n",
       "\n",
       "         [[-0.5615,  0.0058,  0.0560,  ..., -0.0128, -0.0081, -0.0263],\n",
       "          [-1.1010, -0.4310, -0.5415,  ...,  0.5956, -0.3098, -0.0754],\n",
       "          [-1.2214, -0.3840, -0.8149,  ...,  0.2019, -0.2697,  0.7818],\n",
       "          [-0.5082,  0.5707, -0.8850,  ...,  0.4637, -0.1240,  0.8361]],\n",
       "\n",
       "         [[-0.0095,  0.0916, -0.0365,  ...,  0.0816,  0.0484, -0.0297],\n",
       "          [ 0.3735,  0.7328,  0.1410,  ..., -0.5264, -0.4943, -1.1611],\n",
       "          [-0.6001,  0.8347, -0.7125,  ..., -0.2972,  0.1885,  0.1032],\n",
       "          [ 0.0905,  0.5984,  0.0745,  ..., -0.0688, -1.5383,  0.2929]]]])), (tensor([[[[-4.7609e-02, -2.3298e+00,  1.3318e-01,  ..., -2.0184e-01,\n",
       "           -2.0948e-01,  1.3572e-01],\n",
       "          [-1.4494e+00,  4.6508e+00,  4.3481e-01,  ..., -2.0429e-01,\n",
       "            2.6626e-01,  1.7415e+00],\n",
       "          [-7.3942e-01,  3.5294e+00,  1.4805e+00,  ..., -9.8342e-01,\n",
       "            7.8799e-01,  8.4571e-01],\n",
       "          [-1.4148e+00,  5.2583e+00,  6.9008e-01,  ...,  8.0271e-01,\n",
       "            7.2812e-01,  2.8336e-01]],\n",
       "\n",
       "         [[-7.8644e-01,  2.1306e-01,  4.7874e-01,  ..., -5.1547e-01,\n",
       "            1.0604e+00,  1.1233e+00],\n",
       "          [ 2.5677e+00,  5.2386e-01,  2.4146e+00,  ...,  8.9336e-01,\n",
       "            1.0760e+00,  3.5632e-01],\n",
       "          [ 1.3740e+00,  7.2956e-01,  1.7975e+00,  ..., -2.1788e-01,\n",
       "            5.0426e-01, -1.0579e+00],\n",
       "          [ 4.5169e-01,  5.9713e-01,  1.5820e+00,  ..., -5.0392e-01,\n",
       "            8.3292e-01,  9.4861e-01]],\n",
       "\n",
       "         [[-8.4063e-01,  4.6717e-01, -1.1738e-04,  ...,  5.0188e-01,\n",
       "           -2.1832e-01,  1.1777e+00],\n",
       "          [ 5.5853e-01, -1.3954e+00,  8.8799e-01,  ...,  7.7997e-01,\n",
       "            1.1672e+00, -1.6544e-01],\n",
       "          [ 1.4738e+00, -1.0576e+00, -1.8080e-01,  ...,  4.8530e-01,\n",
       "            2.4501e+00, -1.7117e-01],\n",
       "          [ 1.4844e+00, -1.1045e+00,  8.8370e-01,  ...,  8.9252e-01,\n",
       "            2.0749e+00, -1.7247e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4068e-01, -1.1861e-01,  1.3860e-01,  ...,  2.0241e-01,\n",
       "            1.7648e+00, -2.8689e+00],\n",
       "          [ 4.7733e-01,  3.4896e-01,  6.8319e-01,  ...,  2.4146e-01,\n",
       "           -5.3011e+00,  5.2507e+00],\n",
       "          [-1.8030e-01, -2.4334e-01,  5.6821e-02,  ...,  1.5138e-01,\n",
       "           -4.3236e+00,  5.1823e+00],\n",
       "          [-5.7148e-01, -1.6803e+00,  8.8411e-01,  ..., -2.7739e-01,\n",
       "           -4.0738e+00,  5.7366e+00]],\n",
       "\n",
       "         [[ 1.7995e-01,  3.3761e-01,  2.1449e-01,  ..., -2.0088e-01,\n",
       "           -2.9831e-03, -1.4062e-01],\n",
       "          [-7.4316e-01, -1.3689e+00, -1.8893e-01,  ..., -4.7425e-02,\n",
       "           -7.9800e-01, -9.8811e-01],\n",
       "          [-1.2596e+00, -1.6059e+00,  3.0514e-01,  ...,  7.3005e-01,\n",
       "           -1.2218e+00,  1.6595e-01],\n",
       "          [-1.2869e+00, -2.1547e+00, -1.7644e-01,  ...,  1.4134e+00,\n",
       "           -1.0029e+00, -4.3076e-01]],\n",
       "\n",
       "         [[ 3.7180e-01,  1.0626e-01,  5.9969e-01,  ...,  5.4372e-01,\n",
       "            5.8084e-01, -3.0998e-01],\n",
       "          [ 1.0383e+00, -1.3939e+00, -2.0153e+00,  ..., -2.0738e+00,\n",
       "           -4.9582e+00,  1.4178e+00],\n",
       "          [ 4.9466e-01, -1.3655e+00, -2.3301e+00,  ..., -2.5533e+00,\n",
       "           -5.7789e+00,  1.1475e+00],\n",
       "          [ 2.9777e-01, -2.0653e+00, -1.1194e+00,  ..., -2.3816e+00,\n",
       "           -5.8833e+00,  4.0622e-01]]]]), tensor([[[[ 5.7048e-02, -7.9017e-03, -1.9486e-02,  ...,  8.2268e-02,\n",
       "           -9.0540e-02, -4.4395e-02],\n",
       "          [-9.5026e-01, -1.0280e+00,  7.8387e-01,  ..., -4.4570e-01,\n",
       "            1.4411e+00,  1.0463e+00],\n",
       "          [ 2.4910e-01, -6.5660e-01, -1.1293e+00,  ...,  2.9198e-01,\n",
       "            7.9679e-01,  7.5527e-03],\n",
       "          [-6.2321e-01, -1.5343e-01,  5.8764e-01,  ..., -1.0005e-01,\n",
       "            8.2899e-01, -1.2926e+00]],\n",
       "\n",
       "         [[-1.4192e-03,  2.7555e-02,  3.9486e-02,  ..., -3.7081e-02,\n",
       "            4.8346e-02, -2.2668e-02],\n",
       "          [-9.3727e-01, -5.4472e-01, -8.5969e-01,  ...,  2.3337e-01,\n",
       "           -1.3362e+00, -3.7970e-02],\n",
       "          [-9.0722e-01, -9.9270e-03,  8.5870e-01,  ...,  2.0067e+00,\n",
       "           -1.7939e-02,  1.0989e+00],\n",
       "          [ 8.2629e-02, -1.6844e+00, -1.0619e+00,  ...,  1.6383e+00,\n",
       "            5.9838e-02, -2.1210e+00]],\n",
       "\n",
       "         [[ 4.8418e-02, -4.0146e-02,  8.8323e-02,  ...,  4.6365e-02,\n",
       "           -5.4314e-02, -7.6908e-02],\n",
       "          [ 5.1448e-01,  8.2104e-01, -1.3618e+00,  ..., -8.0479e-01,\n",
       "            5.0521e-01, -8.3895e-01],\n",
       "          [ 1.0642e-03,  4.9680e-02, -8.1751e-01,  ..., -1.3411e-02,\n",
       "            1.6234e+00,  1.1391e-01],\n",
       "          [-4.9084e-01, -5.3653e-02,  5.0216e-01,  ..., -1.7277e-01,\n",
       "            5.3778e-01, -1.3619e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.5575e-02, -5.8525e-02,  5.0423e-02,  ..., -4.0100e-02,\n",
       "            3.3816e-02,  2.4114e-04],\n",
       "          [ 1.4668e+00,  3.1029e-01, -7.5179e-02,  ...,  1.1270e+00,\n",
       "           -1.9288e+00,  1.2359e+00],\n",
       "          [ 8.7535e-01,  2.3277e-01,  1.4702e+00,  ...,  7.5275e-01,\n",
       "           -2.7102e-01,  5.7917e-01],\n",
       "          [ 1.2378e+00, -1.3522e+00,  9.0799e-03,  ...,  5.2855e-01,\n",
       "           -5.6743e-01,  3.8394e-02]],\n",
       "\n",
       "         [[ 1.6289e-01, -6.1140e-02,  1.6375e-01,  ...,  8.3989e-02,\n",
       "           -9.1427e-03, -1.4528e-01],\n",
       "          [ 1.1677e+00,  3.0939e-01, -2.2328e-01,  ...,  1.9940e+00,\n",
       "            1.4364e+00, -5.7669e-01],\n",
       "          [ 3.3554e-01, -2.6362e-01,  4.6107e-01,  ...,  1.3101e-01,\n",
       "            4.7598e-01,  1.3880e-01],\n",
       "          [ 1.1172e+00, -4.2702e-02,  2.8641e-01,  ...,  1.9960e+00,\n",
       "           -1.5612e-01, -1.6840e+00]],\n",
       "\n",
       "         [[ 2.0728e-01, -3.0708e-02, -7.1395e-02,  ..., -4.8225e-03,\n",
       "            6.4186e-02,  2.4669e-02],\n",
       "          [ 3.9993e-01,  9.2404e-01,  6.1534e-01,  ..., -7.5126e-01,\n",
       "           -2.2139e-01,  3.8161e-01],\n",
       "          [ 3.5468e-01, -9.9702e-02,  4.8790e-01,  ..., -7.2126e-01,\n",
       "           -5.1211e-01,  4.7671e-01],\n",
       "          [ 3.6180e-01, -2.2226e-01,  4.6695e-01,  ..., -7.6258e-02,\n",
       "           -2.8419e-01, -5.6679e-01]]]])), (tensor([[[[ 3.3476e-02, -2.0756e-01, -4.5774e-01,  ...,  2.8457e-01,\n",
       "            3.0339e-01,  3.8771e-01],\n",
       "          [-1.3142e+00,  1.8887e+00, -9.8255e-01,  ...,  6.6852e-01,\n",
       "            5.7019e-01,  1.6259e+00],\n",
       "          [-4.8710e-01,  9.4562e-01, -6.9331e-01,  ...,  2.7993e-02,\n",
       "           -1.0543e-01,  1.1406e+00],\n",
       "          [-6.9772e-01,  1.3805e+00, -5.3300e-01,  ...,  1.0576e+00,\n",
       "            8.2762e-01,  2.9108e+00]],\n",
       "\n",
       "         [[-2.6799e-01,  1.6816e-01,  1.2650e-01,  ...,  5.0865e-02,\n",
       "           -1.1203e+00, -1.6860e-01],\n",
       "          [-3.5018e-01,  1.3851e+00,  9.3764e-01,  ...,  4.7201e-01,\n",
       "            4.1560e-01, -4.5811e-01],\n",
       "          [-2.2200e-01,  3.4938e-01, -5.4304e-01,  ...,  1.1916e+00,\n",
       "            1.0779e+00,  5.1201e-01],\n",
       "          [-1.7953e+00,  5.7254e-01,  1.0399e-01,  ...,  1.5869e-01,\n",
       "            7.7698e-01, -1.3326e+00]],\n",
       "\n",
       "         [[-1.2060e+00, -1.2209e-01,  5.5866e-01,  ..., -6.2827e-01,\n",
       "            4.5335e-01, -2.9346e-01],\n",
       "          [ 5.1784e-01,  6.6589e-01,  1.0798e+00,  ..., -1.8672e-01,\n",
       "            1.0740e+00, -2.5560e-03],\n",
       "          [ 2.1295e+00, -8.6874e-02, -2.0015e-01,  ...,  3.1301e-01,\n",
       "            7.8220e-01,  6.8674e-01],\n",
       "          [ 1.5889e+00,  2.7046e+00,  5.7252e-01,  ...,  1.1926e+00,\n",
       "            1.4171e+00,  6.2580e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.7443e-01, -9.0996e-01, -3.7751e-01,  ..., -1.0076e+00,\n",
       "           -4.0771e-01,  4.8802e-01],\n",
       "          [ 3.5916e-01, -7.2113e-01,  1.0121e+00,  ..., -1.4757e-01,\n",
       "            1.8822e+00, -1.9231e+00],\n",
       "          [ 1.7504e+00, -5.8389e-01, -4.6812e-01,  ...,  7.6723e-01,\n",
       "            1.0379e+00, -1.1100e+00],\n",
       "          [ 8.0206e-02,  1.2274e+00, -1.9568e-01,  ...,  7.5109e-01,\n",
       "            1.4524e+00, -3.7356e-01]],\n",
       "\n",
       "         [[-9.1085e-01,  2.5734e+00,  2.8149e-01,  ...,  3.5107e-01,\n",
       "            1.9510e+00, -4.8665e-01],\n",
       "          [ 1.2418e+00, -3.2012e+00, -1.6197e-01,  ...,  4.6038e-02,\n",
       "           -6.1974e+00,  2.3817e+00],\n",
       "          [ 2.6351e+00, -2.6823e+00,  3.8654e-01,  ..., -7.0956e-01,\n",
       "           -4.7805e+00,  2.1984e-01],\n",
       "          [-1.5153e-01, -3.0820e+00,  1.8656e+00,  ...,  6.3620e-01,\n",
       "           -5.8425e+00,  1.9127e+00]],\n",
       "\n",
       "         [[-1.9839e+00, -3.5837e-01, -1.1141e+00,  ..., -3.8468e-01,\n",
       "            6.9629e-02,  2.4673e-01],\n",
       "          [ 2.9570e+00,  2.4088e-01,  1.0020e+00,  ..., -4.2444e-01,\n",
       "            9.9395e-01,  1.5545e+00],\n",
       "          [ 3.9225e+00, -1.3899e+00,  5.3375e-01,  ..., -8.7716e-01,\n",
       "            3.4436e-01, -6.3568e-01],\n",
       "          [ 3.2214e+00,  8.1684e-01,  6.7754e-01,  ...,  1.1424e+00,\n",
       "           -2.4129e-01,  1.9308e-02]]]]), tensor([[[[-5.3250e-02, -7.6478e-02,  2.0734e-02,  ...,  9.6583e-02,\n",
       "           -2.8793e-02,  3.1824e-02],\n",
       "          [-4.8248e-01,  3.4473e-01,  6.1249e-01,  ..., -4.2296e-01,\n",
       "           -1.0688e+00,  8.4801e-01],\n",
       "          [-7.8665e-02,  4.4514e-01,  1.1117e+00,  ..., -4.3445e-01,\n",
       "           -1.4102e+00,  4.2241e-01],\n",
       "          [-1.6185e+00,  5.3814e-01,  1.5741e+00,  ..., -7.4480e-01,\n",
       "            2.2929e-02, -2.2353e-01]],\n",
       "\n",
       "         [[ 2.1788e-02, -6.7176e-03, -5.9651e-02,  ...,  1.6018e-02,\n",
       "            2.4732e-02,  4.2729e-02],\n",
       "          [ 3.6972e-01,  8.6293e-01,  3.8909e-01,  ...,  4.1530e-01,\n",
       "           -8.3719e-01,  1.0244e+00],\n",
       "          [-5.9750e-02,  1.3340e+00,  5.0878e-01,  ..., -4.6525e-01,\n",
       "           -1.1484e+00, -1.1532e-01],\n",
       "          [-8.5352e-02,  1.9757e+00, -4.0278e-01,  ..., -9.4492e-01,\n",
       "            3.2980e-01,  3.2581e-01]],\n",
       "\n",
       "         [[ 1.0057e-02,  2.1553e-02, -6.1820e-02,  ...,  2.1963e-02,\n",
       "            2.6441e-03,  4.4758e-02],\n",
       "          [-4.9782e-01,  5.1162e-01, -8.3719e-01,  ...,  1.2806e+00,\n",
       "            8.9592e-01,  1.9520e+00],\n",
       "          [-2.4860e-01,  4.2454e-01,  1.5880e-01,  ...,  1.2481e+00,\n",
       "           -2.8269e-01,  4.6689e-01],\n",
       "          [-6.4449e-01,  1.1205e+00, -4.3247e-01,  ...,  1.8238e+00,\n",
       "            1.0589e+00,  9.7927e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6900e-02, -8.3389e-03, -7.8417e-02,  ..., -8.1075e-03,\n",
       "           -3.4916e-02,  2.2717e-02],\n",
       "          [-1.1221e-02,  3.4470e-01, -2.4198e-01,  ...,  1.0243e+00,\n",
       "           -1.0358e-01, -1.2643e+00],\n",
       "          [-4.7387e-01,  9.0677e-01,  7.2489e-01,  ...,  1.1197e+00,\n",
       "           -3.0863e-01,  1.0462e+00],\n",
       "          [ 9.4540e-02,  8.2303e-01,  1.5978e+00,  ..., -1.3585e-01,\n",
       "            1.4407e+00, -1.1254e+00]],\n",
       "\n",
       "         [[-7.3224e-02, -5.1827e-02,  2.8097e-02,  ...,  3.5235e-03,\n",
       "           -6.0216e-02, -1.1983e-01],\n",
       "          [ 3.1280e-01, -2.4861e+00, -4.8812e-01,  ...,  3.3452e-01,\n",
       "           -1.2364e+00, -1.0622e+00],\n",
       "          [-1.5533e-01, -1.9817e+00,  4.6484e-03,  ...,  9.5988e-02,\n",
       "           -8.5010e-01, -2.3280e-01],\n",
       "          [ 2.0670e-01, -1.6765e+00, -7.8459e-01,  ...,  4.6656e-01,\n",
       "           -7.1951e-01, -2.9514e-01]],\n",
       "\n",
       "         [[ 2.1838e-02,  3.1282e-02, -9.7240e-02,  ..., -2.3251e-02,\n",
       "           -1.4750e-02, -1.3885e-02],\n",
       "          [ 1.2960e+00, -7.6237e-04,  2.5663e-01,  ...,  1.3930e+00,\n",
       "            6.8402e-01, -1.6250e+00],\n",
       "          [ 8.6530e-02, -2.3460e-01,  7.2314e-01,  ...,  6.1757e-01,\n",
       "           -1.1112e+00, -1.2775e+00],\n",
       "          [-7.2584e-02,  8.4841e-01, -1.0933e+00,  ...,  4.4626e-01,\n",
       "           -1.8697e-01, -6.0079e-01]]]])), (tensor([[[[-0.5132,  0.4685, -0.8413,  ..., -1.0296, -1.3473,  0.1739],\n",
       "          [ 0.9687, -0.8250,  0.8571,  ...,  4.4005, -1.1040, -2.0649],\n",
       "          [ 2.3633, -0.7075,  1.7762,  ...,  3.2651, -0.0833, -1.7829],\n",
       "          [ 0.4552, -0.1650,  0.6127,  ...,  3.1487, -1.5274, -2.8744]],\n",
       "\n",
       "         [[ 0.8574, -2.0743,  0.1421,  ...,  0.2578, -2.4628, -0.4386],\n",
       "          [ 2.9122,  2.0336,  0.1948,  ...,  0.5988,  0.9194, -0.6398],\n",
       "          [ 2.0571,  2.9717, -1.4210,  ..., -0.1337,  2.7770, -1.3632],\n",
       "          [ 2.6379,  2.6550, -1.2010,  ...,  1.2525,  1.7610, -3.3329]],\n",
       "\n",
       "         [[ 1.0115,  0.3936, -0.1630,  ..., -0.8035, -1.3686, -0.3736],\n",
       "          [-0.1807,  0.4730, -1.5536,  ...,  1.5788, -0.3099, -0.1765],\n",
       "          [ 0.1849,  0.0729, -0.6395,  ...,  1.8559,  0.2417,  0.3757],\n",
       "          [-0.9612,  1.1037, -0.6524,  ...,  2.2408, -0.8124,  0.4771]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2073, -0.5542,  0.4692,  ..., -0.6287,  1.0578,  0.2538],\n",
       "          [-1.5880,  1.3457, -1.5381,  ..., -1.8357, -0.9708, -0.6701],\n",
       "          [-1.0512,  0.4748, -1.4718,  ..., -2.0487, -1.2425, -1.7273],\n",
       "          [-2.3826,  0.7856, -1.8255,  ..., -1.1950, -2.7341, -1.0173]],\n",
       "\n",
       "         [[ 0.2602,  0.5421,  0.5200,  ...,  0.7546,  0.0703,  0.7996],\n",
       "          [ 0.6309,  2.4310, -0.9485,  ...,  0.3932, -0.1605,  0.2841],\n",
       "          [-1.4367,  2.2208, -1.0280,  ..., -0.9959, -0.0417, -0.2677],\n",
       "          [-1.1435,  1.9931, -0.2184,  ...,  1.4027, -0.1347,  1.5666]],\n",
       "\n",
       "         [[-0.7075,  0.3313, -1.5489,  ..., -0.4046,  0.2383, -1.3149],\n",
       "          [-1.7321,  0.3697, -0.2821,  ...,  0.0393, -0.6486,  2.0461],\n",
       "          [-1.5046,  1.9261, -1.6806,  ..., -1.0721,  1.2721,  1.8826],\n",
       "          [ 1.0264,  0.0153, -1.1006,  ..., -1.0993, -0.1499,  3.0787]]]]), tensor([[[[-0.0193,  0.0956, -0.0735,  ...,  0.0800, -0.0401, -0.0783],\n",
       "          [-1.1223, -0.1148,  1.5729,  ..., -1.2535,  0.0279,  1.8700],\n",
       "          [-1.1871,  0.0361,  1.2338,  ..., -0.3349,  0.6026, -0.6838],\n",
       "          [-0.4974,  1.6071,  1.5548,  ...,  0.3402, -0.9317, -0.5980]],\n",
       "\n",
       "         [[ 0.0355,  0.0412,  0.0438,  ..., -0.0495, -0.0375, -0.0635],\n",
       "          [ 2.7485,  1.2378,  0.1289,  ...,  0.3027, -0.2163, -2.9276],\n",
       "          [ 0.3701,  0.2209,  1.0868,  ...,  0.9893,  0.5835, -0.1979],\n",
       "          [ 0.8909, -0.5449,  0.3681,  ..., -1.3809, -0.2603, -2.6149]],\n",
       "\n",
       "         [[ 0.0162,  0.0395, -0.0519,  ...,  0.0059,  0.0227,  0.0439],\n",
       "          [ 0.4097,  1.2373, -0.9182,  ...,  2.0594, -0.9253, -0.7049],\n",
       "          [-0.3196, -0.2240, -0.6877,  ..., -0.3508, -0.3471, -0.5196],\n",
       "          [-0.7635,  2.4524, -0.2621,  ..., -1.0063,  1.3019, -0.2316]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1198,  0.0534, -0.0255,  ..., -0.0210,  0.0402,  0.0678],\n",
       "          [-0.5727,  0.2118,  1.5672,  ...,  1.1086, -0.0320, -0.1453],\n",
       "          [-0.7227, -0.2614,  1.9396,  ...,  0.6165,  0.1267, -0.7651],\n",
       "          [-0.6321, -0.0977,  1.8734,  ...,  0.5365, -1.5176,  0.6340]],\n",
       "\n",
       "         [[ 0.1021,  0.0222,  0.0047,  ..., -0.0361,  0.0632,  0.0572],\n",
       "          [-0.3573,  0.2430, -1.3016,  ...,  1.0952, -0.3630,  0.3954],\n",
       "          [ 0.0635, -0.9096,  0.1533,  ...,  0.6274,  1.4501,  0.0664],\n",
       "          [ 0.1905, -0.0220,  0.2031,  ..., -0.2826,  1.6738, -0.6330]],\n",
       "\n",
       "         [[-0.1053, -0.0305, -0.0790,  ..., -0.0748,  0.0751,  0.0163],\n",
       "          [-0.4686,  0.2327,  0.0958,  ..., -0.1521,  1.1185,  0.8968],\n",
       "          [-0.0281, -0.8963, -1.2389,  ...,  0.3113,  1.7975, -0.6054],\n",
       "          [-0.1729, -0.4510,  0.5374,  ..., -0.6831,  1.4352,  0.8017]]]])), (tensor([[[[-1.6684e+00, -3.1542e-01, -3.2523e-01,  ...,  1.2944e-01,\n",
       "            3.2948e-01, -4.6706e-01],\n",
       "          [ 5.4347e-01, -7.0560e-01, -9.0639e-01,  ..., -2.5334e-01,\n",
       "           -1.2723e+00,  6.6226e-01],\n",
       "          [-2.8399e-01, -2.1269e+00,  1.0415e-01,  ...,  5.7512e-01,\n",
       "           -9.5043e-01,  9.1895e-01],\n",
       "          [ 1.3198e+00,  3.0151e-01, -6.8131e-04,  ...,  5.1266e-01,\n",
       "           -9.1878e-01,  4.5077e-01]],\n",
       "\n",
       "         [[ 1.0452e-01, -8.0842e-02,  2.3180e+00,  ...,  2.9560e-01,\n",
       "            5.1354e-02, -1.7986e-01],\n",
       "          [ 3.5854e-01,  1.3944e-01, -2.1866e-02,  ...,  7.6113e-01,\n",
       "           -1.9168e-01, -4.3932e-01],\n",
       "          [ 3.3985e-01, -1.5937e+00, -1.0144e+00,  ...,  1.0292e+00,\n",
       "            1.3459e-04,  3.4252e-01],\n",
       "          [ 5.8953e-01, -1.4085e+00, -1.6560e-01,  ...,  5.1703e-01,\n",
       "           -4.0214e-01, -2.7620e-01]],\n",
       "\n",
       "         [[-1.9591e-01,  1.0470e+00,  4.5357e-01,  ..., -5.5233e-01,\n",
       "            2.7011e-01, -1.1917e-01],\n",
       "          [-8.5493e-01,  6.5305e-01, -6.6367e-01,  ...,  8.0717e-01,\n",
       "           -2.9630e-01,  5.0119e-02],\n",
       "          [-1.4899e-01,  3.5272e-02, -1.0173e+00,  ...,  1.2967e+00,\n",
       "            1.0949e+00,  7.6452e-01],\n",
       "          [ 1.0890e-01,  7.1880e-01,  6.4426e-01,  ...,  2.9186e+00,\n",
       "            1.0600e-01, -5.2943e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.8405e-01,  9.9656e-01, -8.6540e-01,  ..., -7.6774e-01,\n",
       "            7.4873e-01,  8.6664e-01],\n",
       "          [ 5.1138e-01,  5.3223e-01, -1.6431e+00,  ..., -1.1658e+00,\n",
       "            1.9169e-01,  1.6850e+00],\n",
       "          [-1.8170e-01, -5.2443e-01, -3.8861e-01,  ..., -5.6112e-01,\n",
       "            7.3807e-01,  6.7519e-01],\n",
       "          [ 9.8744e-01,  1.9791e+00, -3.9736e-01,  ..., -7.3357e-01,\n",
       "            2.1922e+00,  2.8293e-01]],\n",
       "\n",
       "         [[-4.0214e-01,  3.3870e-01,  3.5777e-01,  ...,  7.3630e-01,\n",
       "            1.8217e-02, -7.5666e-02],\n",
       "          [-3.5893e-01,  1.3256e-01, -3.6543e-02,  ...,  1.1286e+00,\n",
       "           -1.5669e+00,  1.4251e-01],\n",
       "          [-9.6650e-01, -1.3253e-02,  6.5338e-01,  ..., -1.4987e-02,\n",
       "           -1.4020e+00,  6.2209e-01],\n",
       "          [-7.9356e-01,  7.2404e-01,  2.6540e-01,  ...,  9.2829e-01,\n",
       "           -5.3375e-01,  4.6197e-01]],\n",
       "\n",
       "         [[-6.9028e-01,  8.8657e-03,  4.5415e-01,  ..., -1.2779e-01,\n",
       "           -6.5137e-03, -1.1899e-01],\n",
       "          [-5.2226e-02, -1.4052e+00,  7.2835e-01,  ..., -1.5415e+00,\n",
       "           -1.8050e+00, -3.1376e-02],\n",
       "          [-4.1346e-01, -1.7272e+00, -2.5112e-01,  ..., -5.4229e-01,\n",
       "           -3.4421e+00,  6.8974e-03],\n",
       "          [-2.8761e-01,  1.3464e-01,  1.2959e+00,  ..., -1.2881e+00,\n",
       "           -1.8487e+00, -4.0989e-01]]]]), tensor([[[[ 0.1069, -0.1334, -0.1931,  ..., -0.3115,  0.3135, -0.1604],\n",
       "          [ 2.4788,  0.5180,  2.0527,  ...,  3.2371, -2.3208,  1.3394],\n",
       "          [ 1.3256,  0.0286,  1.7286,  ...,  1.0314, -1.8874,  1.7796],\n",
       "          [ 1.7601, -0.8448,  1.4155,  ...,  0.2107, -0.7242, -0.5129]],\n",
       "\n",
       "         [[ 0.1086,  0.0143,  0.0862,  ..., -0.0761, -0.1751,  0.1992],\n",
       "          [-0.0059,  0.1167,  1.6704,  ..., -0.3239, -0.0468, -0.5200],\n",
       "          [-1.6769,  0.9309,  2.2668,  ..., -1.4244, -2.3132,  0.1872],\n",
       "          [-0.9144,  1.4388,  0.8177,  ...,  0.4580, -1.1311, -0.3513]],\n",
       "\n",
       "         [[-0.0402, -0.0120,  0.0040,  ...,  0.0595,  0.0700,  0.0193],\n",
       "          [ 1.9184, -0.3447, -1.1417,  ...,  1.4984,  0.8703, -0.4458],\n",
       "          [ 1.0406,  1.3541, -1.5813,  ...,  0.4368,  1.5937, -1.6574],\n",
       "          [-1.3196, -0.4722, -1.1879,  ...,  0.5502,  0.4061,  1.3492]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0192, -0.0591,  0.0954,  ...,  0.0599, -0.0334, -0.0240],\n",
       "          [-0.4546, -0.3072,  1.7675,  ..., -0.6256, -1.0731,  0.6480],\n",
       "          [-1.4373,  1.2958,  0.6705,  ..., -0.3505,  0.7310, -0.7993],\n",
       "          [-1.4568,  2.2920, -0.3353,  ...,  1.0735,  0.7838,  0.3189]],\n",
       "\n",
       "         [[-0.2611, -0.0895,  0.1080,  ..., -0.1094, -0.0053, -0.1327],\n",
       "          [-0.0632,  1.5662, -0.3494,  ..., -0.1078, -0.3137,  0.5213],\n",
       "          [-1.3857,  1.1066,  1.4875,  ...,  0.1494, -0.2502, -0.5066],\n",
       "          [-0.9354, -0.4122,  0.8512,  ...,  0.5787, -0.8807, -1.2520]],\n",
       "\n",
       "         [[ 0.0777, -0.0588,  0.0833,  ..., -0.1031,  0.0460, -0.1281],\n",
       "          [-0.8091, -0.3881, -0.3980,  ...,  0.4954,  0.9193, -0.6813],\n",
       "          [-0.1094, -0.9774, -0.4159,  ...,  0.1553, -0.2723,  0.6529],\n",
       "          [ 0.0366,  1.2191, -0.7306,  ..., -1.7935, -0.6570,  0.6395]]]]))), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[7454, 2402,  257,  640]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/h/brandon/internship/Uncover_implicit_bias/gpt2_training/train2.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://localhost:12000/h/brandon/internship/Uncover_implicit_bias/gpt2_training/train2.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tokenizer\u001b[39m.\u001b[39;49mdecode(outputs, clean_up_tokenization_spaces\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, skip_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3345\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3342\u001b[0m \u001b[39m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   3343\u001b[0m token_ids \u001b[39m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 3345\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decode(\n\u001b[1;32m   3346\u001b[0m     token_ids\u001b[39m=\u001b[39;49mtoken_ids,\n\u001b[1;32m   3347\u001b[0m     skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens,\n\u001b[1;32m   3348\u001b[0m     clean_up_tokenization_spaces\u001b[39m=\u001b[39;49mclean_up_tokenization_spaces,\n\u001b[1;32m   3349\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3350\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/tokenization_utils.py:931\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decode\u001b[39m(\n\u001b[1;32m    922\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    923\u001b[0m     token_ids: List[\u001b[39mint\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    928\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode_use_source_tokenizer \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39muse_source_tokenizer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 931\u001b[0m     filtered_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_ids_to_tokens(token_ids, skip_special_tokens\u001b[39m=\u001b[39;49mskip_special_tokens)\n\u001b[1;32m    933\u001b[0m     \u001b[39m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[39;00m\n\u001b[1;32m    934\u001b[0m     \u001b[39m# we need to build string separately for added tokens and byte-level tokens\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     \u001b[39m# cf. https://github.com/huggingface/transformers/issues/1133\u001b[39;00m\n\u001b[1;32m    936\u001b[0m     sub_texts \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/tokenization_utils.py:906\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m    904\u001b[0m tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m    905\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m ids:\n\u001b[0;32m--> 906\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(index)\n\u001b[1;32m    907\u001b[0m     \u001b[39mif\u001b[39;00m skip_special_tokens \u001b[39mand\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_special_ids:\n\u001b[1;32m    908\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(outputs, clean_up_tokenization_spaces=True, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/h/brandon/internship/Uncover_implicit_bias/gpt2_training/train2.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://localhost:12000/h/brandon/internship/Uncover_implicit_bias/gpt2_training/train2.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m outputs\u001b[39m.\u001b[39;49mlogits\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutputWithPastAndCrossAttentions' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "outputs.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[7454, 2402,  257,  640]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/h/brandon/internship/Uncover_implicit_bias/gpt2_training/train2.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://localhost:12000/h/brandon/internship/Uncover_implicit_bias/gpt2_training/train2.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model(\u001b[39m'\u001b[39;49m\u001b[39mhello\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/pkgs/pytorch-2.0-cuda-11.8-python3.9/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:771\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    770\u001b[0m \u001b[39melif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     input_shape \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39;49msize()\n\u001b[1;32m    772\u001b[0m     input_ids \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, input_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    773\u001b[0m     batch_size \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /h/brandon/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /h/brandon/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /h/brandon/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /h/brandon/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /h/brandon/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "# loss = outputs.loss\n",
    "# logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -35.2362,  -35.3265,  -38.9753,  ...,  -44.4644,  -43.9974,\n",
       "           -36.4579],\n",
       "         [-112.6172, -114.5832, -116.5725,  ..., -119.0129, -118.8059,\n",
       "          -111.6918],\n",
       "         [ -88.7435,  -89.8644,  -93.1977,  ...,  -92.3839,  -96.1782,\n",
       "           -92.1273],\n",
       "         [ -85.1647,  -88.3380,  -92.8703,  ...,  -99.8017,  -94.7657,\n",
       "           -90.9330],\n",
       "         [-116.7280, -119.3949, -121.7259,  ..., -129.1003, -124.6102,\n",
       "          -121.6092],\n",
       "         [ -77.4425,  -80.4463,  -88.0498,  ...,  -96.2564,  -93.6345,\n",
       "           -84.0666]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50259, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
